{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AiProcess/torch_deep_rl/blob/main/05_getting_started_first_training_loop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtEnOVgQ0uCb"
      },
      "source": [
        "\n",
        "# Get started with your own first training loop\n",
        "\n",
        "**Author**: [Vincent Moens](https://github.com/vmoens)\n",
        "\n",
        "\n",
        "<div class=\"alert alert-info\"><h4>Note</h4><p>To run this tutorial in a notebook, add an installation cell\n",
        "  at the beginning containing:\n",
        "\n",
        "```\n",
        "!pip install tensordict\n",
        "!pip install torchrl</p></div>\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensordict\n",
        "!pip install torchrl"
      ],
      "metadata": {
        "id": "Y8pFjmxb1g3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchvision"
      ],
      "metadata": {
        "id": "W6L_Vm7G8OBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CdpmHI90uCg"
      },
      "source": [
        "Time to wrap up everything we've learned so far in this Getting Started\n",
        "series!\n",
        "\n",
        "In this tutorial, we will be writing the most basic training loop there is\n",
        "using only components we have presented in the previous lessons.\n",
        "\n",
        "We'll be using DQN with a CartPole environment as a prototypical example.\n",
        "\n",
        "We will be voluntarily keeping the verbosity to its minimum, only linking\n",
        "each section to the related tutorial.\n",
        "\n",
        "## Building the environment\n",
        "\n",
        "We'll be using a gym environment with a :class:`~torchrl.envs.transforms.StepCounter`\n",
        "transform. If you need a refresher, check our these features are presented in\n",
        "`the environment tutorial <gs_env_ted>`.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NucII5U30uCh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6644bc84-d378-4037-b6be-45671fdab049"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorDict(\n",
            "    fields={\n",
            "        action: Tensor(shape=torch.Size([10, 2]), device=cpu, dtype=torch.int64, is_shared=False),\n",
            "        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        next: TensorDict(\n",
            "            fields={\n",
            "                done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "                observation: Tensor(shape=torch.Size([10, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                reward: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                step_count: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
            "                terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "                truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "            batch_size=torch.Size([10]),\n",
            "            device=None,\n",
            "            is_shared=False),\n",
            "        observation: Tensor(shape=torch.Size([10, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "        step_count: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
            "        terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "    batch_size=torch.Size([10]),\n",
            "    device=None,\n",
            "    is_shared=False)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "import time\n",
        "\n",
        "from torchrl.envs import GymEnv, StepCounter, TransformedEnv\n",
        "\n",
        "env = TransformedEnv(GymEnv(\"CartPole-v1\"), StepCounter())\n",
        "env.set_seed(0)\n",
        "\n",
        "td = env.rollout(max_steps=10)\n",
        "print(td)\n",
        "# print(td['next','step_count'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVHaRQTV0uCj"
      },
      "source": [
        "## Designing a policy\n",
        "\n",
        "The next step is to build our policy.\n",
        "We'll be making a regular, deterministic\n",
        "version of the actor to be used within the\n",
        "`loss module <gs_optim>` and during\n",
        "`evaluation <gs_logging>`.\n",
        "Next, we will augment it with an exploration module\n",
        "for `inference <gs_storage>`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-tDfwsn80uCj"
      },
      "outputs": [],
      "source": [
        "from tensordict.nn import TensorDictModule as Mod, TensorDictSequential as Seq\n",
        "from torchrl.modules import EGreedyModule, MLP, QValueModule\n",
        "\n",
        "value_mlp = MLP(out_features=env.action_spec.shape[-1], num_cells=[64, 64])\n",
        "value_net = Mod(value_mlp, in_keys=[\"observation\"], out_keys=[\"action_value\"])\n",
        "policy = Seq(value_net, QValueModule(spec=env.action_spec))\n",
        "exploration_module = EGreedyModule(\n",
        "    env.action_spec, annealing_num_steps=100_000, eps_init=0.5\n",
        ")\n",
        "policy_explore = Seq(policy, exploration_module)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(policy_explore)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeW-S1Nf5aU1",
        "outputId": "ff30b28c-6b08-4b30-e880-55a91439534c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorDictSequential(\n",
            "    module=ModuleList(\n",
            "      (0): TensorDictSequential(\n",
            "          module=ModuleList(\n",
            "            (0): TensorDictModule(\n",
            "                module=MLP(\n",
            "                  (0): LazyLinear(in_features=0, out_features=64, bias=True)\n",
            "                  (1): Tanh()\n",
            "                  (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "                  (3): Tanh()\n",
            "                  (4): Linear(in_features=64, out_features=2, bias=True)\n",
            "                ),\n",
            "                device=cpu,\n",
            "                in_keys=['observation'],\n",
            "                out_keys=['action_value'])\n",
            "            (1): QValueModule()\n",
            "          ),\n",
            "          device=cpu,\n",
            "          in_keys=['observation'],\n",
            "          out_keys=['action', 'action_value', 'chosen_action_value'])\n",
            "      (1): EGreedyModule()\n",
            "    ),\n",
            "    device=cpu,\n",
            "    in_keys=['observation'],\n",
            "    out_keys=['action_value', 'chosen_action_value', 'action'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nYj1yFo0uCk"
      },
      "source": [
        "## Data Collector and replay buffer\n",
        "\n",
        "Here comes the data part: we need a\n",
        "`data collector <gs_storage_collector>` to easily get batches of data\n",
        "and a `replay buffer <gs_storage_rb>` to store that data for training.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GrepRjLO0uCk"
      },
      "outputs": [],
      "source": [
        "from torchrl.collectors import SyncDataCollector\n",
        "from torchrl.data import LazyTensorStorage, ReplayBuffer\n",
        "\n",
        "init_rand_steps = 5000\n",
        "frames_per_batch = 100\n",
        "optim_steps = 10\n",
        "collector = SyncDataCollector(\n",
        "    env,\n",
        "    policy,\n",
        "    frames_per_batch=frames_per_batch,\n",
        "    total_frames=-1,\n",
        "    init_random_frames=init_rand_steps,\n",
        ")\n",
        "rb = ReplayBuffer(storage=LazyTensorStorage(100_000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIfMZih_0uCl"
      },
      "source": [
        "## Loss module and optimizer\n",
        "\n",
        "We build our loss as indicated in the `dedicated tutorial <gs_optim>`, with\n",
        "its optimizer and target parameter updater:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bukokEVU0uCl"
      },
      "outputs": [],
      "source": [
        "from torch.optim import Adam\n",
        "from torchrl.objectives import DQNLoss, SoftUpdate\n",
        "\n",
        "loss = DQNLoss(value_network=policy, action_space=env.action_spec, delay_value=True)\n",
        "optim = Adam(loss.parameters(), lr=0.02)\n",
        "updater = SoftUpdate(loss, eps=0.99)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGgNETbq0uCm"
      },
      "source": [
        "## Logger\n",
        "\n",
        "We'll be using a CSV logger to log our results, and save rendered videos.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IS-HM9-t0uCm"
      },
      "outputs": [],
      "source": [
        "from torchrl._utils import logger as torchrl_logger\n",
        "from torchrl.record import CSVLogger, VideoRecorder\n",
        "\n",
        "path = \"./training_loop\"\n",
        "logger = CSVLogger(exp_name=\"dqn\", log_dir=path, video_format=\"mp4\")\n",
        "video_recorder = VideoRecorder(logger, tag=\"video\")\n",
        "record_env = TransformedEnv(\n",
        "    GymEnv(\"CartPole-v1\", from_pixels=True, pixels_only=False), video_recorder\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dO6FqLC0uCn"
      },
      "source": [
        "## Training loop\n",
        "\n",
        "Instead of fixing a specific number of iterations to run, we will keep on\n",
        "training the network until it reaches a certain performance (arbitrarily\n",
        "defined as 200 steps in the environment -- with CartPole, success is defined\n",
        "as having longer trajectories).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "nv0vRB8P0uCn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca582ffa-c112-4bbe-c434-669659981afe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-08-15 12:06:38,401 [torchrl][INFO] Max num steps: 100, rb length 5200\n",
            "2024-08-15 12:06:38,419 [torchrl][INFO] Max num steps: 100, rb length 5200\n",
            "2024-08-15 12:06:38,432 [torchrl][INFO] Max num steps: 100, rb length 5200\n",
            "2024-08-15 12:06:38,444 [torchrl][INFO] Max num steps: 100, rb length 5200\n",
            "2024-08-15 12:06:38,456 [torchrl][INFO] Max num steps: 100, rb length 5200\n",
            "2024-08-15 12:06:38,469 [torchrl][INFO] Max num steps: 100, rb length 5200\n",
            "2024-08-15 12:06:38,481 [torchrl][INFO] Max num steps: 100, rb length 5200\n",
            "2024-08-15 12:06:38,493 [torchrl][INFO] Max num steps: 100, rb length 5200\n",
            "2024-08-15 12:06:38,506 [torchrl][INFO] Max num steps: 100, rb length 5200\n",
            "2024-08-15 12:06:38,518 [torchrl][INFO] Max num steps: 100, rb length 5200\n",
            "2024-08-15 12:06:38,621 [torchrl][INFO] Max num steps: 100, rb length 5300\n",
            "2024-08-15 12:06:38,636 [torchrl][INFO] Max num steps: 100, rb length 5300\n",
            "2024-08-15 12:06:38,652 [torchrl][INFO] Max num steps: 100, rb length 5300\n",
            "2024-08-15 12:06:38,667 [torchrl][INFO] Max num steps: 100, rb length 5300\n",
            "2024-08-15 12:06:38,684 [torchrl][INFO] Max num steps: 100, rb length 5300\n",
            "2024-08-15 12:06:38,699 [torchrl][INFO] Max num steps: 100, rb length 5300\n",
            "2024-08-15 12:06:38,712 [torchrl][INFO] Max num steps: 100, rb length 5300\n",
            "2024-08-15 12:06:38,724 [torchrl][INFO] Max num steps: 100, rb length 5300\n",
            "2024-08-15 12:06:38,736 [torchrl][INFO] Max num steps: 100, rb length 5300\n",
            "2024-08-15 12:06:38,748 [torchrl][INFO] Max num steps: 100, rb length 5300\n",
            "2024-08-15 12:06:38,848 [torchrl][INFO] Max num steps: 100, rb length 5400\n",
            "2024-08-15 12:06:38,860 [torchrl][INFO] Max num steps: 100, rb length 5400\n",
            "2024-08-15 12:06:38,873 [torchrl][INFO] Max num steps: 100, rb length 5400\n",
            "2024-08-15 12:06:38,885 [torchrl][INFO] Max num steps: 100, rb length 5400\n",
            "2024-08-15 12:06:38,898 [torchrl][INFO] Max num steps: 100, rb length 5400\n",
            "2024-08-15 12:06:38,910 [torchrl][INFO] Max num steps: 100, rb length 5400\n",
            "2024-08-15 12:06:38,923 [torchrl][INFO] Max num steps: 100, rb length 5400\n",
            "2024-08-15 12:06:38,936 [torchrl][INFO] Max num steps: 100, rb length 5400\n",
            "2024-08-15 12:06:38,948 [torchrl][INFO] Max num steps: 100, rb length 5400\n",
            "2024-08-15 12:06:38,965 [torchrl][INFO] Max num steps: 100, rb length 5400\n",
            "2024-08-15 12:06:39,101 [torchrl][INFO] Max num steps: 100, rb length 5500\n",
            "2024-08-15 12:06:39,116 [torchrl][INFO] Max num steps: 100, rb length 5500\n",
            "2024-08-15 12:06:39,132 [torchrl][INFO] Max num steps: 100, rb length 5500\n",
            "2024-08-15 12:06:39,148 [torchrl][INFO] Max num steps: 100, rb length 5500\n",
            "2024-08-15 12:06:39,163 [torchrl][INFO] Max num steps: 100, rb length 5500\n",
            "2024-08-15 12:06:39,178 [torchrl][INFO] Max num steps: 100, rb length 5500\n",
            "2024-08-15 12:06:39,193 [torchrl][INFO] Max num steps: 100, rb length 5500\n",
            "2024-08-15 12:06:39,208 [torchrl][INFO] Max num steps: 100, rb length 5500\n",
            "2024-08-15 12:06:39,224 [torchrl][INFO] Max num steps: 100, rb length 5500\n",
            "2024-08-15 12:06:39,238 [torchrl][INFO] Max num steps: 100, rb length 5500\n",
            "2024-08-15 12:06:39,335 [torchrl][INFO] Max num steps: 100, rb length 5600\n",
            "2024-08-15 12:06:39,347 [torchrl][INFO] Max num steps: 100, rb length 5600\n",
            "2024-08-15 12:06:39,358 [torchrl][INFO] Max num steps: 100, rb length 5600\n",
            "2024-08-15 12:06:39,370 [torchrl][INFO] Max num steps: 100, rb length 5600\n",
            "2024-08-15 12:06:39,382 [torchrl][INFO] Max num steps: 100, rb length 5600\n",
            "2024-08-15 12:06:39,397 [torchrl][INFO] Max num steps: 100, rb length 5600\n",
            "2024-08-15 12:06:39,413 [torchrl][INFO] Max num steps: 100, rb length 5600\n",
            "2024-08-15 12:06:39,426 [torchrl][INFO] Max num steps: 100, rb length 5600\n",
            "2024-08-15 12:06:39,439 [torchrl][INFO] Max num steps: 100, rb length 5600\n",
            "2024-08-15 12:06:39,451 [torchrl][INFO] Max num steps: 100, rb length 5600\n",
            "2024-08-15 12:06:39,548 [torchrl][INFO] Max num steps: 100, rb length 5700\n",
            "2024-08-15 12:06:39,561 [torchrl][INFO] Max num steps: 100, rb length 5700\n",
            "2024-08-15 12:06:39,574 [torchrl][INFO] Max num steps: 100, rb length 5700\n",
            "2024-08-15 12:06:39,586 [torchrl][INFO] Max num steps: 100, rb length 5700\n",
            "2024-08-15 12:06:39,602 [torchrl][INFO] Max num steps: 100, rb length 5700\n",
            "2024-08-15 12:06:39,620 [torchrl][INFO] Max num steps: 100, rb length 5700\n",
            "2024-08-15 12:06:39,635 [torchrl][INFO] Max num steps: 100, rb length 5700\n",
            "2024-08-15 12:06:39,651 [torchrl][INFO] Max num steps: 100, rb length 5700\n",
            "2024-08-15 12:06:39,667 [torchrl][INFO] Max num steps: 100, rb length 5700\n",
            "2024-08-15 12:06:39,683 [torchrl][INFO] Max num steps: 100, rb length 5700\n",
            "2024-08-15 12:06:39,806 [torchrl][INFO] Max num steps: 100, rb length 5800\n",
            "2024-08-15 12:06:39,821 [torchrl][INFO] Max num steps: 100, rb length 5800\n",
            "2024-08-15 12:06:39,833 [torchrl][INFO] Max num steps: 100, rb length 5800\n",
            "2024-08-15 12:06:39,845 [torchrl][INFO] Max num steps: 100, rb length 5800\n",
            "2024-08-15 12:06:39,857 [torchrl][INFO] Max num steps: 100, rb length 5800\n",
            "2024-08-15 12:06:39,869 [torchrl][INFO] Max num steps: 100, rb length 5800\n",
            "2024-08-15 12:06:39,882 [torchrl][INFO] Max num steps: 100, rb length 5800\n",
            "2024-08-15 12:06:39,896 [torchrl][INFO] Max num steps: 100, rb length 5800\n",
            "2024-08-15 12:06:39,908 [torchrl][INFO] Max num steps: 100, rb length 5800\n",
            "2024-08-15 12:06:39,921 [torchrl][INFO] Max num steps: 100, rb length 5800\n",
            "2024-08-15 12:06:40,040 [torchrl][INFO] Max num steps: 100, rb length 5900\n",
            "2024-08-15 12:06:40,054 [torchrl][INFO] Max num steps: 100, rb length 5900\n",
            "2024-08-15 12:06:40,069 [torchrl][INFO] Max num steps: 100, rb length 5900\n",
            "2024-08-15 12:06:40,085 [torchrl][INFO] Max num steps: 100, rb length 5900\n",
            "2024-08-15 12:06:40,100 [torchrl][INFO] Max num steps: 100, rb length 5900\n",
            "2024-08-15 12:06:40,115 [torchrl][INFO] Max num steps: 100, rb length 5900\n",
            "2024-08-15 12:06:40,129 [torchrl][INFO] Max num steps: 100, rb length 5900\n",
            "2024-08-15 12:06:40,143 [torchrl][INFO] Max num steps: 100, rb length 5900\n",
            "2024-08-15 12:06:40,159 [torchrl][INFO] Max num steps: 100, rb length 5900\n",
            "2024-08-15 12:06:40,175 [torchrl][INFO] Max num steps: 100, rb length 5900\n",
            "2024-08-15 12:06:40,297 [torchrl][INFO] Max num steps: 100, rb length 6000\n",
            "2024-08-15 12:06:40,313 [torchrl][INFO] Max num steps: 100, rb length 6000\n",
            "2024-08-15 12:06:40,325 [torchrl][INFO] Max num steps: 100, rb length 6000\n",
            "2024-08-15 12:06:40,337 [torchrl][INFO] Max num steps: 100, rb length 6000\n",
            "2024-08-15 12:06:40,349 [torchrl][INFO] Max num steps: 100, rb length 6000\n",
            "2024-08-15 12:06:40,361 [torchrl][INFO] Max num steps: 100, rb length 6000\n",
            "2024-08-15 12:06:40,373 [torchrl][INFO] Max num steps: 100, rb length 6000\n",
            "2024-08-15 12:06:40,386 [torchrl][INFO] Max num steps: 100, rb length 6000\n",
            "2024-08-15 12:06:40,398 [torchrl][INFO] Max num steps: 100, rb length 6000\n",
            "2024-08-15 12:06:40,410 [torchrl][INFO] Max num steps: 100, rb length 6000\n",
            "2024-08-15 12:06:40,692 [torchrl][INFO] Max num steps: 100, rb length 6200\n",
            "2024-08-15 12:06:40,704 [torchrl][INFO] Max num steps: 100, rb length 6200\n",
            "2024-08-15 12:06:40,715 [torchrl][INFO] Max num steps: 100, rb length 6200\n",
            "2024-08-15 12:06:40,727 [torchrl][INFO] Max num steps: 100, rb length 6200\n",
            "2024-08-15 12:06:40,739 [torchrl][INFO] Max num steps: 100, rb length 6200\n",
            "2024-08-15 12:06:40,750 [torchrl][INFO] Max num steps: 100, rb length 6200\n",
            "2024-08-15 12:06:40,762 [torchrl][INFO] Max num steps: 100, rb length 6200\n",
            "2024-08-15 12:06:40,774 [torchrl][INFO] Max num steps: 100, rb length 6200\n",
            "2024-08-15 12:06:40,788 [torchrl][INFO] Max num steps: 100, rb length 6200\n",
            "2024-08-15 12:06:40,800 [torchrl][INFO] Max num steps: 100, rb length 6200\n",
            "2024-08-15 12:06:40,901 [torchrl][INFO] Max num steps: 100, rb length 6300\n",
            "2024-08-15 12:06:40,916 [torchrl][INFO] Max num steps: 100, rb length 6300\n",
            "2024-08-15 12:06:40,930 [torchrl][INFO] Max num steps: 100, rb length 6300\n",
            "2024-08-15 12:06:40,943 [torchrl][INFO] Max num steps: 100, rb length 6300\n",
            "2024-08-15 12:06:40,955 [torchrl][INFO] Max num steps: 100, rb length 6300\n",
            "2024-08-15 12:06:40,968 [torchrl][INFO] Max num steps: 100, rb length 6300\n",
            "2024-08-15 12:06:40,981 [torchrl][INFO] Max num steps: 100, rb length 6300\n",
            "2024-08-15 12:06:40,993 [torchrl][INFO] Max num steps: 100, rb length 6300\n",
            "2024-08-15 12:06:41,008 [torchrl][INFO] Max num steps: 100, rb length 6300\n",
            "2024-08-15 12:06:41,026 [torchrl][INFO] Max num steps: 100, rb length 6300\n",
            "2024-08-15 12:06:41,151 [torchrl][INFO] Max num steps: 100, rb length 6400\n",
            "2024-08-15 12:06:41,168 [torchrl][INFO] Max num steps: 100, rb length 6400\n",
            "2024-08-15 12:06:41,184 [torchrl][INFO] Max num steps: 100, rb length 6400\n",
            "2024-08-15 12:06:41,198 [torchrl][INFO] Max num steps: 100, rb length 6400\n",
            "2024-08-15 12:06:41,212 [torchrl][INFO] Max num steps: 100, rb length 6400\n",
            "2024-08-15 12:06:41,224 [torchrl][INFO] Max num steps: 100, rb length 6400\n",
            "2024-08-15 12:06:41,236 [torchrl][INFO] Max num steps: 100, rb length 6400\n",
            "2024-08-15 12:06:41,246 [torchrl][INFO] Max num steps: 100, rb length 6400\n",
            "2024-08-15 12:06:41,258 [torchrl][INFO] Max num steps: 100, rb length 6400\n",
            "2024-08-15 12:06:41,271 [torchrl][INFO] Max num steps: 100, rb length 6400\n",
            "2024-08-15 12:06:41,375 [torchrl][INFO] Max num steps: 100, rb length 6500\n",
            "2024-08-15 12:06:41,391 [torchrl][INFO] Max num steps: 100, rb length 6500\n",
            "2024-08-15 12:06:41,407 [torchrl][INFO] Max num steps: 100, rb length 6500\n",
            "2024-08-15 12:06:41,422 [torchrl][INFO] Max num steps: 100, rb length 6500\n",
            "2024-08-15 12:06:41,438 [torchrl][INFO] Max num steps: 100, rb length 6500\n",
            "2024-08-15 12:06:41,450 [torchrl][INFO] Max num steps: 100, rb length 6500\n",
            "2024-08-15 12:06:41,462 [torchrl][INFO] Max num steps: 100, rb length 6500\n",
            "2024-08-15 12:06:41,476 [torchrl][INFO] Max num steps: 100, rb length 6500\n",
            "2024-08-15 12:06:41,491 [torchrl][INFO] Max num steps: 100, rb length 6500\n",
            "2024-08-15 12:06:41,504 [torchrl][INFO] Max num steps: 100, rb length 6500\n",
            "2024-08-15 12:06:41,596 [torchrl][INFO] Max num steps: 100, rb length 6600\n",
            "2024-08-15 12:06:41,611 [torchrl][INFO] Max num steps: 100, rb length 6600\n",
            "2024-08-15 12:06:41,628 [torchrl][INFO] Max num steps: 100, rb length 6600\n",
            "2024-08-15 12:06:41,646 [torchrl][INFO] Max num steps: 100, rb length 6600\n",
            "2024-08-15 12:06:41,659 [torchrl][INFO] Max num steps: 100, rb length 6600\n",
            "2024-08-15 12:06:41,672 [torchrl][INFO] Max num steps: 100, rb length 6600\n",
            "2024-08-15 12:06:41,688 [torchrl][INFO] Max num steps: 100, rb length 6600\n",
            "2024-08-15 12:06:41,703 [torchrl][INFO] Max num steps: 100, rb length 6600\n",
            "2024-08-15 12:06:41,719 [torchrl][INFO] Max num steps: 100, rb length 6600\n",
            "2024-08-15 12:06:41,735 [torchrl][INFO] Max num steps: 100, rb length 6600\n",
            "2024-08-15 12:06:41,837 [torchrl][INFO] Max num steps: 100, rb length 6700\n",
            "2024-08-15 12:06:41,849 [torchrl][INFO] Max num steps: 100, rb length 6700\n",
            "2024-08-15 12:06:41,861 [torchrl][INFO] Max num steps: 100, rb length 6700\n",
            "2024-08-15 12:06:41,873 [torchrl][INFO] Max num steps: 100, rb length 6700\n",
            "2024-08-15 12:06:41,885 [torchrl][INFO] Max num steps: 100, rb length 6700\n",
            "2024-08-15 12:06:41,898 [torchrl][INFO] Max num steps: 100, rb length 6700\n",
            "2024-08-15 12:06:41,911 [torchrl][INFO] Max num steps: 100, rb length 6700\n",
            "2024-08-15 12:06:41,924 [torchrl][INFO] Max num steps: 100, rb length 6700\n",
            "2024-08-15 12:06:41,937 [torchrl][INFO] Max num steps: 100, rb length 6700\n",
            "2024-08-15 12:06:41,949 [torchrl][INFO] Max num steps: 100, rb length 6700\n",
            "2024-08-15 12:06:42,073 [torchrl][INFO] Max num steps: 100, rb length 6800\n",
            "2024-08-15 12:06:42,092 [torchrl][INFO] Max num steps: 100, rb length 6800\n",
            "2024-08-15 12:06:42,108 [torchrl][INFO] Max num steps: 100, rb length 6800\n",
            "2024-08-15 12:06:42,124 [torchrl][INFO] Max num steps: 100, rb length 6800\n",
            "2024-08-15 12:06:42,137 [torchrl][INFO] Max num steps: 100, rb length 6800\n",
            "2024-08-15 12:06:42,153 [torchrl][INFO] Max num steps: 100, rb length 6800\n",
            "2024-08-15 12:06:42,172 [torchrl][INFO] Max num steps: 100, rb length 6800\n",
            "2024-08-15 12:06:42,190 [torchrl][INFO] Max num steps: 100, rb length 6800\n",
            "2024-08-15 12:06:42,207 [torchrl][INFO] Max num steps: 100, rb length 6800\n",
            "2024-08-15 12:06:42,226 [torchrl][INFO] Max num steps: 100, rb length 6800\n",
            "2024-08-15 12:06:42,356 [torchrl][INFO] Max num steps: 100, rb length 6900\n",
            "2024-08-15 12:06:42,372 [torchrl][INFO] Max num steps: 100, rb length 6900\n",
            "2024-08-15 12:06:42,390 [torchrl][INFO] Max num steps: 100, rb length 6900\n",
            "2024-08-15 12:06:42,406 [torchrl][INFO] Max num steps: 100, rb length 6900\n",
            "2024-08-15 12:06:42,420 [torchrl][INFO] Max num steps: 100, rb length 6900\n",
            "2024-08-15 12:06:42,433 [torchrl][INFO] Max num steps: 100, rb length 6900\n",
            "2024-08-15 12:06:42,445 [torchrl][INFO] Max num steps: 100, rb length 6900\n",
            "2024-08-15 12:06:42,457 [torchrl][INFO] Max num steps: 100, rb length 6900\n",
            "2024-08-15 12:06:42,469 [torchrl][INFO] Max num steps: 100, rb length 6900\n",
            "2024-08-15 12:06:42,484 [torchrl][INFO] Max num steps: 100, rb length 6900\n",
            "2024-08-15 12:06:42,594 [torchrl][INFO] Max num steps: 116, rb length 7000\n",
            "2024-08-15 12:06:42,608 [torchrl][INFO] Max num steps: 116, rb length 7000\n",
            "2024-08-15 12:06:42,622 [torchrl][INFO] Max num steps: 116, rb length 7000\n",
            "2024-08-15 12:06:42,634 [torchrl][INFO] Max num steps: 116, rb length 7000\n",
            "2024-08-15 12:06:42,646 [torchrl][INFO] Max num steps: 116, rb length 7000\n",
            "2024-08-15 12:06:42,658 [torchrl][INFO] Max num steps: 116, rb length 7000\n",
            "2024-08-15 12:06:42,670 [torchrl][INFO] Max num steps: 116, rb length 7000\n",
            "2024-08-15 12:06:42,682 [torchrl][INFO] Max num steps: 116, rb length 7000\n",
            "2024-08-15 12:06:42,694 [torchrl][INFO] Max num steps: 116, rb length 7000\n",
            "2024-08-15 12:06:42,706 [torchrl][INFO] Max num steps: 116, rb length 7000\n",
            "2024-08-15 12:06:42,960 [torchrl][INFO] Max num steps: 131, rb length 7200\n",
            "2024-08-15 12:06:42,972 [torchrl][INFO] Max num steps: 131, rb length 7200\n",
            "2024-08-15 12:06:42,984 [torchrl][INFO] Max num steps: 131, rb length 7200\n",
            "2024-08-15 12:06:42,996 [torchrl][INFO] Max num steps: 131, rb length 7200\n",
            "2024-08-15 12:06:43,013 [torchrl][INFO] Max num steps: 131, rb length 7200\n",
            "2024-08-15 12:06:43,027 [torchrl][INFO] Max num steps: 131, rb length 7200\n",
            "2024-08-15 12:06:43,042 [torchrl][INFO] Max num steps: 131, rb length 7200\n",
            "2024-08-15 12:06:43,058 [torchrl][INFO] Max num steps: 131, rb length 7200\n",
            "2024-08-15 12:06:43,074 [torchrl][INFO] Max num steps: 131, rb length 7200\n",
            "2024-08-15 12:06:43,088 [torchrl][INFO] Max num steps: 131, rb length 7200\n",
            "2024-08-15 12:06:43,209 [torchrl][INFO] Max num steps: 131, rb length 7300\n",
            "2024-08-15 12:06:43,222 [torchrl][INFO] Max num steps: 131, rb length 7300\n",
            "2024-08-15 12:06:43,233 [torchrl][INFO] Max num steps: 131, rb length 7300\n",
            "2024-08-15 12:06:43,246 [torchrl][INFO] Max num steps: 131, rb length 7300\n",
            "2024-08-15 12:06:43,260 [torchrl][INFO] Max num steps: 131, rb length 7300\n",
            "2024-08-15 12:06:43,275 [torchrl][INFO] Max num steps: 131, rb length 7300\n",
            "2024-08-15 12:06:43,290 [torchrl][INFO] Max num steps: 131, rb length 7300\n",
            "2024-08-15 12:06:43,305 [torchrl][INFO] Max num steps: 131, rb length 7300\n",
            "2024-08-15 12:06:43,319 [torchrl][INFO] Max num steps: 131, rb length 7300\n",
            "2024-08-15 12:06:43,334 [torchrl][INFO] Max num steps: 131, rb length 7300\n",
            "2024-08-15 12:06:43,438 [torchrl][INFO] Max num steps: 131, rb length 7400\n",
            "2024-08-15 12:06:43,450 [torchrl][INFO] Max num steps: 131, rb length 7400\n",
            "2024-08-15 12:06:43,463 [torchrl][INFO] Max num steps: 131, rb length 7400\n",
            "2024-08-15 12:06:43,475 [torchrl][INFO] Max num steps: 131, rb length 7400\n",
            "2024-08-15 12:06:43,488 [torchrl][INFO] Max num steps: 131, rb length 7400\n",
            "2024-08-15 12:06:43,500 [torchrl][INFO] Max num steps: 131, rb length 7400\n",
            "2024-08-15 12:06:43,512 [torchrl][INFO] Max num steps: 131, rb length 7400\n",
            "2024-08-15 12:06:43,532 [torchrl][INFO] Max num steps: 131, rb length 7400\n",
            "2024-08-15 12:06:43,548 [torchrl][INFO] Max num steps: 131, rb length 7400\n",
            "2024-08-15 12:06:43,559 [torchrl][INFO] Max num steps: 131, rb length 7400\n",
            "2024-08-15 12:06:43,665 [torchrl][INFO] Max num steps: 131, rb length 7500\n",
            "2024-08-15 12:06:43,681 [torchrl][INFO] Max num steps: 131, rb length 7500\n",
            "2024-08-15 12:06:43,694 [torchrl][INFO] Max num steps: 131, rb length 7500\n",
            "2024-08-15 12:06:43,706 [torchrl][INFO] Max num steps: 131, rb length 7500\n",
            "2024-08-15 12:06:43,719 [torchrl][INFO] Max num steps: 131, rb length 7500\n",
            "2024-08-15 12:06:43,731 [torchrl][INFO] Max num steps: 131, rb length 7500\n",
            "2024-08-15 12:06:43,743 [torchrl][INFO] Max num steps: 131, rb length 7500\n",
            "2024-08-15 12:06:43,755 [torchrl][INFO] Max num steps: 131, rb length 7500\n",
            "2024-08-15 12:06:43,766 [torchrl][INFO] Max num steps: 131, rb length 7500\n",
            "2024-08-15 12:06:43,780 [torchrl][INFO] Max num steps: 131, rb length 7500\n",
            "2024-08-15 12:06:43,873 [torchrl][INFO] Max num steps: 131, rb length 7600\n",
            "2024-08-15 12:06:43,885 [torchrl][INFO] Max num steps: 131, rb length 7600\n",
            "2024-08-15 12:06:43,897 [torchrl][INFO] Max num steps: 131, rb length 7600\n",
            "2024-08-15 12:06:43,909 [torchrl][INFO] Max num steps: 131, rb length 7600\n",
            "2024-08-15 12:06:43,921 [torchrl][INFO] Max num steps: 131, rb length 7600\n",
            "2024-08-15 12:06:43,934 [torchrl][INFO] Max num steps: 131, rb length 7600\n",
            "2024-08-15 12:06:43,946 [torchrl][INFO] Max num steps: 131, rb length 7600\n",
            "2024-08-15 12:06:43,959 [torchrl][INFO] Max num steps: 131, rb length 7600\n",
            "2024-08-15 12:06:43,971 [torchrl][INFO] Max num steps: 131, rb length 7600\n",
            "2024-08-15 12:06:43,983 [torchrl][INFO] Max num steps: 131, rb length 7600\n",
            "2024-08-15 12:06:44,099 [torchrl][INFO] Max num steps: 169, rb length 7700\n",
            "2024-08-15 12:06:44,113 [torchrl][INFO] Max num steps: 169, rb length 7700\n",
            "2024-08-15 12:06:44,127 [torchrl][INFO] Max num steps: 169, rb length 7700\n",
            "2024-08-15 12:06:44,141 [torchrl][INFO] Max num steps: 169, rb length 7700\n",
            "2024-08-15 12:06:44,162 [torchrl][INFO] Max num steps: 169, rb length 7700\n",
            "2024-08-15 12:06:44,182 [torchrl][INFO] Max num steps: 169, rb length 7700\n",
            "2024-08-15 12:06:44,196 [torchrl][INFO] Max num steps: 169, rb length 7700\n",
            "2024-08-15 12:06:44,210 [torchrl][INFO] Max num steps: 169, rb length 7700\n",
            "2024-08-15 12:06:44,224 [torchrl][INFO] Max num steps: 169, rb length 7700\n",
            "2024-08-15 12:06:44,239 [torchrl][INFO] Max num steps: 169, rb length 7700\n",
            "2024-08-15 12:06:44,346 [torchrl][INFO] Max num steps: 229, rb length 7800\n",
            "2024-08-15 12:06:44,358 [torchrl][INFO] Max num steps: 229, rb length 7800\n",
            "2024-08-15 12:06:44,370 [torchrl][INFO] Max num steps: 229, rb length 7800\n",
            "2024-08-15 12:06:44,383 [torchrl][INFO] Max num steps: 229, rb length 7800\n",
            "2024-08-15 12:06:44,395 [torchrl][INFO] Max num steps: 229, rb length 7800\n",
            "2024-08-15 12:06:44,407 [torchrl][INFO] Max num steps: 229, rb length 7800\n",
            "2024-08-15 12:06:44,419 [torchrl][INFO] Max num steps: 229, rb length 7800\n",
            "2024-08-15 12:06:44,432 [torchrl][INFO] Max num steps: 229, rb length 7800\n",
            "2024-08-15 12:06:44,447 [torchrl][INFO] Max num steps: 229, rb length 7800\n",
            "2024-08-15 12:06:44,458 [torchrl][INFO] Max num steps: 229, rb length 7800\n",
            "2024-08-15 12:06:44,462 [torchrl][INFO] solved after 28000 steps, 1420 episodes and in 10.633612871170044s.\n"
          ]
        }
      ],
      "source": [
        "total_count = 0\n",
        "total_episodes = 0\n",
        "t0 = time.time()\n",
        "for i, data in enumerate(collector):\n",
        "    # Write data in replay buffer\n",
        "    rb.extend(data)\n",
        "    max_length = rb[:][\"next\", \"step_count\"].max()\n",
        "    if len(rb) > init_rand_steps:\n",
        "        # Optim loop (we do several optim steps\n",
        "        # per batch collected for efficiency)\n",
        "        for _ in range(optim_steps):\n",
        "            sample = rb.sample(128)\n",
        "            loss_vals = loss(sample)\n",
        "            loss_vals[\"loss\"].backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            # Update exploration factor\n",
        "            exploration_module.step(data.numel())\n",
        "            # Update target params\n",
        "            updater.step()\n",
        "            if i % 10:\n",
        "                torchrl_logger.info(f\"Max num steps: {max_length}, rb length {len(rb)}\")\n",
        "            total_count += data.numel()\n",
        "            total_episodes += data[\"next\", \"done\"].sum()\n",
        "    if max_length > 200:\n",
        "        break\n",
        "\n",
        "t1 = time.time()\n",
        "\n",
        "torchrl_logger.info(\n",
        "    f\"solved after {total_count} steps, {total_episodes} episodes and in {t1-t0}s.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftzr00n_0uCn"
      },
      "source": [
        "## Rendering\n",
        "\n",
        "Finally, we run the environment for as many steps as we can and save the\n",
        "video locally (notice that we are not exploring).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "On-ga3ut0uCn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "64d0f14c-7348-4dd9-b0ac-ea8f01745279"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-f60cb28fd9e2>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrecord_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvideo_recorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchrl/record/recorder.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, suffix)\u001b[0m\n\u001b[1;32m    251\u001b[0m                 \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"_\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                 self.logger.log_video(\n\u001b[0m\u001b[1;32m    254\u001b[0m                     \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                     \u001b[0mvideo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchrl/record/loggers/csv.py\u001b[0m in \u001b[0;36mlog_video\u001b[0;34m(self, name, video, step, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0;34m\"Wrong format of the video tensor. Should be ((N), T, C, H, W)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             )\n\u001b[0;32m--> 198\u001b[0;31m         self.experiment.add_video(\n\u001b[0m\u001b[1;32m    199\u001b[0m             \u001b[0mtag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0mvid_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchrl/record/loggers/csv.py\u001b[0m in \u001b[0;36madd_video\u001b[0;34m(self, tag, vid_tensor, global_step, **kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mMemoryMappedTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvid_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"mp4\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvid_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_meta_registrations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HAS_OPS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/_meta_registrations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mregister_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"roi_align\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mmeta_roi_align\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrois\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspatial_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maligned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrois\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"rois must have shape as Tensor[K, 5]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     torch._check(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/_meta_registrations.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(fn)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mregister_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverload_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"default\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mget_meta_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverload_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'torchvision' has no attribute 'extension' (most likely due to a circular import)"
          ]
        }
      ],
      "source": [
        "record_env.rollout(max_steps=1000, policy=policy)\n",
        "video_recorder.dump()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIVCzUfX0uCo"
      },
      "source": [
        "This is what your rendered CartPole video will look like after a full\n",
        "training loop:\n",
        "\n",
        ".. figure:: /_static/img/cartpole.gif\n",
        "\n",
        "This concludes our series of \"Getting started with TorchRL\" tutorials!\n",
        "Feel free to share feedback about it on GitHub.\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}