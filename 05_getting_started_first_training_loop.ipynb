{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AiProcess/torch_deep_rl/blob/main/05_getting_started_first_training_loop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtEnOVgQ0uCb"
      },
      "source": [
        "\n",
        "# Get started with your own first training loop\n",
        "\n",
        "**Author**: [Vincent Moens](https://github.com/vmoens)\n",
        "\n",
        "\n",
        "<div class=\"alert alert-info\"><h4>Note</h4><p>To run this tutorial in a notebook, add an installation cell\n",
        "  at the beginning containing:\n",
        "\n",
        "```\n",
        "!pip install tensordict\n",
        "!pip install torchrl</p></div>\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensordict\n",
        "!pip install torchrl"
      ],
      "metadata": {
        "id": "Y8pFjmxb1g3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CdpmHI90uCg"
      },
      "source": [
        "Time to wrap up everything we've learned so far in this Getting Started\n",
        "series!\n",
        "\n",
        "In this tutorial, we will be writing the most basic training loop there is\n",
        "using only components we have presented in the previous lessons.\n",
        "\n",
        "We'll be using DQN with a CartPole environment as a prototypical example.\n",
        "\n",
        "We will be voluntarily keeping the verbosity to its minimum, only linking\n",
        "each section to the related tutorial.\n",
        "\n",
        "## Building the environment\n",
        "\n",
        "We'll be using a gym environment with a :class:`~torchrl.envs.transforms.StepCounter`\n",
        "transform. If you need a refresher, check our these features are presented in\n",
        "`the environment tutorial <gs_env_ted>`.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NucII5U30uCh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd392346-4afa-4c7d-cc2b-6edf3b1733f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorDict(\n",
            "    fields={\n",
            "        action: Tensor(shape=torch.Size([10, 2]), device=cpu, dtype=torch.int64, is_shared=False),\n",
            "        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        next: TensorDict(\n",
            "            fields={\n",
            "                done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "                observation: Tensor(shape=torch.Size([10, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                pixels: Tensor(shape=torch.Size([10, 400, 600, 3]), device=cpu, dtype=torch.uint8, is_shared=False),\n",
            "                reward: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                step_count: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
            "                terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "                truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "            batch_size=torch.Size([10]),\n",
            "            device=None,\n",
            "            is_shared=False),\n",
            "        observation: Tensor(shape=torch.Size([10, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "        pixels: Tensor(shape=torch.Size([10, 400, 600, 3]), device=cpu, dtype=torch.uint8, is_shared=False),\n",
            "        step_count: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
            "        terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "    batch_size=torch.Size([10]),\n",
            "    device=None,\n",
            "    is_shared=False)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "import time\n",
        "\n",
        "from torchrl.envs import GymEnv, StepCounter, TransformedEnv\n",
        "\n",
        "env = TransformedEnv(\n",
        "    GymEnv(\"CartPole-v1\", from_pixels=True, pixels_only=False),\n",
        "    StepCounter()\n",
        ")\n",
        "env.set_seed(0)\n",
        "\n",
        "td = env.rollout(max_steps=10)\n",
        "print(td)\n",
        "# print(td['next','step_count'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVHaRQTV0uCj"
      },
      "source": [
        "## Designing a policy\n",
        "\n",
        "The next step is to build our policy.\n",
        "We'll be making a regular, deterministic\n",
        "version of the actor to be used within the\n",
        "`loss module <gs_optim>` and during\n",
        "`evaluation <gs_logging>`.\n",
        "Next, we will augment it with an exploration module\n",
        "for `inference <gs_storage>`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-tDfwsn80uCj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dd2a7df-fb98-40f2-ddea-2a31c6b4ea57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "from tensordict.nn import TensorDictModule as Mod, TensorDictSequential as Seq\n",
        "from torchrl.modules import EGreedyModule, MLP, QValueModule\n",
        "\n",
        "value_mlp = MLP(out_features=env.action_spec.shape[-1], num_cells=[64, 64])\n",
        "value_net = Mod(value_mlp, in_keys=[\"observation\"], out_keys=[\"action_value\"])\n",
        "policy = Seq(value_net, QValueModule(spec=env.action_spec))\n",
        "exploration_module = EGreedyModule(\n",
        "    env.action_spec, annealing_num_steps=100_000, eps_init=0.5\n",
        ")\n",
        "policy_explore = Seq(policy, exploration_module)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(policy_explore)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeW-S1Nf5aU1",
        "outputId": "44fd019b-c920-464a-ccb2-c6aceb7b2e60"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorDictSequential(\n",
            "    module=ModuleList(\n",
            "      (0): TensorDictSequential(\n",
            "          module=ModuleList(\n",
            "            (0): TensorDictModule(\n",
            "                module=MLP(\n",
            "                  (0): LazyLinear(in_features=0, out_features=64, bias=True)\n",
            "                  (1): Tanh()\n",
            "                  (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "                  (3): Tanh()\n",
            "                  (4): Linear(in_features=64, out_features=2, bias=True)\n",
            "                ),\n",
            "                device=cpu,\n",
            "                in_keys=['observation'],\n",
            "                out_keys=['action_value'])\n",
            "            (1): QValueModule()\n",
            "          ),\n",
            "          device=cpu,\n",
            "          in_keys=['observation'],\n",
            "          out_keys=['action', 'action_value', 'chosen_action_value'])\n",
            "      (1): EGreedyModule()\n",
            "    ),\n",
            "    device=cpu,\n",
            "    in_keys=['observation'],\n",
            "    out_keys=['action_value', 'chosen_action_value', 'action'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nYj1yFo0uCk"
      },
      "source": [
        "## Data Collector and replay buffer\n",
        "\n",
        "Here comes the data part: we need a\n",
        "`data collector <gs_storage_collector>` to easily get batches of data\n",
        "and a `replay buffer <gs_storage_rb>` to store that data for training.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GrepRjLO0uCk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba4ed088-b332-4ecb-e90e-45606f6885ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchrl/collectors/collectors.py:615: UserWarning: init_random_frames (100) is not exactly a multiple of frames_per_batch (8),  this results in more init_random_frames than requested (104).To silence this message, set the environment variable RL_WARNINGS to False.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from torchrl.collectors import SyncDataCollector\n",
        "from torchrl.data import LazyTensorStorage, ReplayBuffer\n",
        "\n",
        "init_rand_steps = 100\n",
        "frames_per_batch = 8\n",
        "optim_steps = 10\n",
        "collector = SyncDataCollector(\n",
        "    env,\n",
        "    policy,\n",
        "    frames_per_batch=frames_per_batch,\n",
        "    total_frames=-1,\n",
        "    init_random_frames=init_rand_steps,\n",
        ")\n",
        "rb = ReplayBuffer(storage=LazyTensorStorage(1000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIfMZih_0uCl"
      },
      "source": [
        "## Loss module and optimizer\n",
        "\n",
        "We build our loss as indicated in the `dedicated tutorial <gs_optim>`, with\n",
        "its optimizer and target parameter updater:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bukokEVU0uCl"
      },
      "outputs": [],
      "source": [
        "from torch.optim import Adam\n",
        "from torchrl.objectives import DQNLoss, SoftUpdate\n",
        "\n",
        "loss = DQNLoss(value_network=policy, action_space=env.action_spec, delay_value=True)\n",
        "optim = Adam(loss.parameters(), lr=0.02)\n",
        "updater = SoftUpdate(loss, eps=0.99)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGgNETbq0uCm"
      },
      "source": [
        "## Logger\n",
        "\n",
        "We'll be using a CSV logger to log our results, and save rendered videos.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "IS-HM9-t0uCm"
      },
      "outputs": [],
      "source": [
        "from torchrl._utils import logger as torchrl_logger\n",
        "from torchrl.record import CSVLogger, VideoRecorder\n",
        "\n",
        "path = \"./training_loop\"\n",
        "logger = CSVLogger(exp_name=\"dqn\", log_dir=path, video_format=\"mp4\")\n",
        "video_recorder = VideoRecorder(logger, tag=\"video\")\n",
        "record_env = TransformedEnv(\n",
        "    GymEnv(\"CartPole-v1\", from_pixels=True, pixels_only=False), video_recorder\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dO6FqLC0uCn"
      },
      "source": [
        "## Training loop\n",
        "\n",
        "Instead of fixing a specific number of iterations to run, we will keep on\n",
        "training the network until it reaches a certain performance (arbitrarily\n",
        "defined as 200 steps in the environment -- with CartPole, success is defined\n",
        "as having longer trajectories).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nv0vRB8P0uCn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80957b93-a89e-48ea-f036-55be0567afc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-08-16 07:58:10,036 [torchrl][INFO] solved after 80 steps, 0 episodes and in 3.298365831375122s.\n"
          ]
        }
      ],
      "source": [
        "total_count = 0\n",
        "total_episodes = 0\n",
        "t0 = time.time()\n",
        "for i, data in enumerate(collector):\n",
        "    # Write data in replay buffer\n",
        "    rb.extend(data)\n",
        "    max_length = rb[:][\"next\", \"step_count\"].max()\n",
        "    if len(rb) > init_rand_steps:\n",
        "        # Optim loop (we do several optim steps\n",
        "        # per batch collected for efficiency)\n",
        "        for _ in range(optim_steps):\n",
        "            sample = rb.sample(128)\n",
        "            loss_vals = loss(sample)\n",
        "            loss_vals[\"loss\"].backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            # Update exploration factor\n",
        "            exploration_module.step(data.numel())\n",
        "            # Update target params\n",
        "            updater.step()\n",
        "            if i % 10:\n",
        "                torchrl_logger.info(f\"Max num steps: {max_length}, rb length {len(rb)}\")\n",
        "            total_count += data.numel()\n",
        "            total_episodes += data[\"next\", \"done\"].sum()\n",
        "    if max_length > 50:\n",
        "        break\n",
        "\n",
        "t1 = time.time()\n",
        "\n",
        "torchrl_logger.info(\n",
        "    f\"solved after {total_count} steps, {total_episodes} episodes and in {t1-t0}s.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftzr00n_0uCn"
      },
      "source": [
        "## Rendering\n",
        "\n",
        "Finally, we run the environment for as many steps as we can and save the\n",
        "video locally (notice that we are not exploring).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "On-ga3ut0uCn"
      },
      "outputs": [],
      "source": [
        "record_env.rollout(max_steps=1000, policy=policy)\n",
        "video_recorder.dump()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIVCzUfX0uCo"
      },
      "source": [
        "This is what your rendered CartPole video will look like after a full\n",
        "training loop:\n",
        "\n",
        ".. figure:: /_static/img/cartpole.gif\n",
        "\n",
        "This concludes our series of \"Getting started with TorchRL\" tutorials!\n",
        "Feel free to share feedback about it on GitHub.\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}