{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AiProcess/torch_deep_rl/blob/main/05_getting_started_first_training_loop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtEnOVgQ0uCb"
      },
      "source": [
        "\n",
        "# Get started with your own first training loop\n",
        "\n",
        "**Author**: [Vincent Moens](https://github.com/vmoens)\n",
        "\n",
        "\n",
        "<div class=\"alert alert-info\"><h4>Note</h4><p>To run this tutorial in a notebook, add an installation cell\n",
        "  at the beginning containing:\n",
        "\n",
        "```\n",
        "!pip install tensordict\n",
        "!pip install torchrl</p></div>\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensordict\n",
        "!pip install torchrl"
      ],
      "metadata": {
        "id": "Y8pFjmxb1g3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CdpmHI90uCg"
      },
      "source": [
        "Time to wrap up everything we've learned so far in this Getting Started\n",
        "series!\n",
        "\n",
        "In this tutorial, we will be writing the most basic training loop there is\n",
        "using only components we have presented in the previous lessons.\n",
        "\n",
        "We'll be using DQN with a CartPole environment as a prototypical example.\n",
        "\n",
        "We will be voluntarily keeping the verbosity to its minimum, only linking\n",
        "each section to the related tutorial.\n",
        "\n",
        "## Building the environment\n",
        "\n",
        "We'll be using a gym environment with a :class:`~torchrl.envs.transforms.StepCounter`\n",
        "transform. If you need a refresher, check our these features are presented in\n",
        "`the environment tutorial <gs_env_ted>`.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NucII5U30uCh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "import time\n",
        "\n",
        "from torchrl.envs import GymEnv\n",
        "from torchrl.envs.transforms import StepCounter, TransformedEnv\n",
        "\n",
        "env = TransformedEnv(\n",
        "    GymEnv(\"CartPole-v1\", from_pixels=True, pixels_only=False),\n",
        "    StepCounter()\n",
        ")\n",
        "env.set_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "td = env.rollout(max_steps=10)\n",
        "print(td)\n",
        "# print(td['step_count'])\n",
        "# print(td['next','step_count'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFcph0c3bDoS",
        "outputId": "0c8d7dde-36e6-40c4-ed3c-395472c0ad6c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorDict(\n",
            "    fields={\n",
            "        action: Tensor(shape=torch.Size([10, 2]), device=cpu, dtype=torch.int64, is_shared=False),\n",
            "        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        next: TensorDict(\n",
            "            fields={\n",
            "                done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "                observation: Tensor(shape=torch.Size([10, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                pixels: Tensor(shape=torch.Size([10, 400, 600, 3]), device=cpu, dtype=torch.uint8, is_shared=False),\n",
            "                reward: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                step_count: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
            "                terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "                truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "            batch_size=torch.Size([10]),\n",
            "            device=None,\n",
            "            is_shared=False),\n",
            "        observation: Tensor(shape=torch.Size([10, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "        pixels: Tensor(shape=torch.Size([10, 400, 600, 3]), device=cpu, dtype=torch.uint8, is_shared=False),\n",
            "        step_count: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
            "        terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "    batch_size=torch.Size([10]),\n",
            "    device=None,\n",
            "    is_shared=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVHaRQTV0uCj"
      },
      "source": [
        "## Designing a policy\n",
        "\n",
        "The next step is to build our policy.\n",
        "We'll be making a regular, deterministic\n",
        "version of the actor to be used within the\n",
        "`loss module <gs_optim>` and during\n",
        "`evaluation <gs_logging>`.\n",
        "Next, we will augment it with an exploration module\n",
        "for `inference <gs_storage>`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.action_spec.shape, env.action_spec.shape[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSUlbomYcT1M",
        "outputId": "02ccf00c-dabe-4dc9-b552-d80dc21512d6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2]), 2)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-tDfwsn80uCj"
      },
      "outputs": [],
      "source": [
        "from tensordict.nn import TensorDictModule, TensorDictSequential\n",
        "from torchrl.modules import EGreedyModule, MLP, QValueModule\n",
        "\n",
        "value_mlp = MLP(out_features=env.action_spec.shape[-1], num_cells=[64, 64])\n",
        "value_net = TensorDictModule(\n",
        "    value_mlp, in_keys=[\"observation\"], out_keys=[\"action_value\"]\n",
        ")\n",
        "policy = TensorDictSequential(\n",
        "    value_net, QValueModule(spec=env.action_spec)\n",
        ")\n",
        "exploration_module = EGreedyModule(\n",
        "    env.action_spec, annealing_num_steps=100_000, eps_init=0.5\n",
        ")\n",
        "policy_explore = TensorDictSequential(\n",
        "    policy, exploration_module\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(policy_explore)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeW-S1Nf5aU1",
        "outputId": "59bfa6d3-6d3f-4103-cd6b-c1f9aeee849f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorDictSequential(\n",
            "    module=ModuleList(\n",
            "      (0): TensorDictSequential(\n",
            "          module=ModuleList(\n",
            "            (0): TensorDictModule(\n",
            "                module=MLP(\n",
            "                  (0): LazyLinear(in_features=0, out_features=64, bias=True)\n",
            "                  (1): Tanh()\n",
            "                  (2): Linear(in_features=64, out_features=64, bias=True)\n",
            "                  (3): Tanh()\n",
            "                  (4): Linear(in_features=64, out_features=2, bias=True)\n",
            "                ),\n",
            "                device=cpu,\n",
            "                in_keys=['observation'],\n",
            "                out_keys=['action_value'])\n",
            "            (1): QValueModule()\n",
            "          ),\n",
            "          device=cpu,\n",
            "          in_keys=['observation'],\n",
            "          out_keys=['action', 'action_value', 'chosen_action_value'])\n",
            "      (1): EGreedyModule()\n",
            "    ),\n",
            "    device=cpu,\n",
            "    in_keys=['observation'],\n",
            "    out_keys=['action_value', 'chosen_action_value', 'action'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nYj1yFo0uCk"
      },
      "source": [
        "## Data Collector and replay buffer\n",
        "\n",
        "Here comes the data part: we need a\n",
        "`data collector <gs_storage_collector>` to easily get batches of data\n",
        "and a `replay buffer <gs_storage_rb>` to store that data for training.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GrepRjLO0uCk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c12cc0e-e427-4c52-889f-8209224ef2ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchrl/collectors/collectors.py:710: UserWarning: init_random_frames (100) is not exactly a multiple of frames_per_batch (8),  this results in more init_random_frames than requested (104).To silence this message, set the environment variable RL_WARNINGS to False.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from torchrl.collectors import SyncDataCollector\n",
        "from torchrl.data import LazyTensorStorage, ReplayBuffer\n",
        "\n",
        "init_rand_steps = 100\n",
        "frames_per_batch = 8\n",
        "optim_steps = 10\n",
        "collector = SyncDataCollector(\n",
        "    env,\n",
        "    policy,\n",
        "    frames_per_batch=frames_per_batch,\n",
        "    total_frames=-1,\n",
        "    init_random_frames=init_rand_steps,\n",
        ")\n",
        "rb = ReplayBuffer(storage=LazyTensorStorage(1000))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIfMZih_0uCl"
      },
      "source": [
        "## Loss module and optimizer\n",
        "\n",
        "We build our loss as indicated in the `dedicated tutorial <gs_optim>`, with\n",
        "its optimizer and target parameter updater:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bukokEVU0uCl"
      },
      "outputs": [],
      "source": [
        "from torch.optim import Adam\n",
        "from torchrl.objectives import DQNLoss, SoftUpdate\n",
        "\n",
        "loss = DQNLoss(value_network=policy, action_space=env.action_spec, delay_value=True)\n",
        "optim = Adam(loss.parameters(), lr=0.02)\n",
        "updater = SoftUpdate(loss, eps=0.99)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGgNETbq0uCm"
      },
      "source": [
        "## Logger\n",
        "\n",
        "We'll be using a CSV logger to log our results, and save rendered videos.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IS-HM9-t0uCm"
      },
      "outputs": [],
      "source": [
        "from torchrl._utils import logger as torchrl_logger\n",
        "from torchrl.record import CSVLogger, VideoRecorder\n",
        "\n",
        "path = \"./training_loop\"\n",
        "logger = CSVLogger(exp_name=\"dqn\", log_dir=path, video_format=\"mp4\")\n",
        "video_recorder = VideoRecorder(logger, tag=\"video\")\n",
        "record_env = TransformedEnv(\n",
        "    GymEnv(\"CartPole-v1\", from_pixels=True, pixels_only=False), video_recorder\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dO6FqLC0uCn"
      },
      "source": [
        "## Training loop\n",
        "\n",
        "Instead of fixing a specific number of iterations to run, we will keep on\n",
        "training the network until it reaches a certain performance (arbitrarily\n",
        "defined as 200 steps in the environment -- with CartPole, success is defined\n",
        "as having longer trajectories).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nv0vRB8P0uCn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ce2ab73-c3eb-416a-8244-32ca4432be7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "2024-11-16 15:37:05,774 [torchrl][INFO] Max num steps: 31, rb length 104\n",
            "2024-11-16 15:37:06,151 [torchrl][INFO] Max num steps: 31, rb length 104\n",
            "2024-11-16 15:37:06,547 [torchrl][INFO] Max num steps: 31, rb length 104\n",
            "2024-11-16 15:37:06,857 [torchrl][INFO] Max num steps: 31, rb length 104\n",
            "2024-11-16 15:37:07,177 [torchrl][INFO] Max num steps: 31, rb length 104\n",
            "2024-11-16 15:37:07,535 [torchrl][INFO] Max num steps: 31, rb length 104\n",
            "2024-11-16 15:37:08,028 [torchrl][INFO] Max num steps: 31, rb length 104\n",
            "2024-11-16 15:37:08,706 [torchrl][INFO] Max num steps: 31, rb length 104\n",
            "2024-11-16 15:37:09,211 [torchrl][INFO] Max num steps: 31, rb length 104\n",
            "2024-11-16 15:37:09,763 [torchrl][INFO] Max num steps: 31, rb length 104\n",
            "2024-11-16 15:37:10,365 [torchrl][INFO] Max num steps: 37, rb length 112\n",
            "2024-11-16 15:37:10,938 [torchrl][INFO] Max num steps: 37, rb length 112\n",
            "2024-11-16 15:37:11,509 [torchrl][INFO] Max num steps: 37, rb length 112\n",
            "2024-11-16 15:37:11,969 [torchrl][INFO] Max num steps: 37, rb length 112\n",
            "2024-11-16 15:37:12,867 [torchrl][INFO] Max num steps: 37, rb length 112\n",
            "2024-11-16 15:37:14,114 [torchrl][INFO] Max num steps: 37, rb length 112\n",
            "2024-11-16 15:37:15,329 [torchrl][INFO] Max num steps: 37, rb length 112\n",
            "2024-11-16 15:37:16,117 [torchrl][INFO] Max num steps: 37, rb length 112\n",
            "2024-11-16 15:37:16,725 [torchrl][INFO] Max num steps: 37, rb length 112\n",
            "2024-11-16 15:37:17,735 [torchrl][INFO] Max num steps: 37, rb length 112\n",
            "2024-11-16 15:37:18,564 [torchrl][INFO] Max num steps: 42, rb length 120\n",
            "2024-11-16 15:37:19,054 [torchrl][INFO] Max num steps: 42, rb length 120\n",
            "2024-11-16 15:37:19,547 [torchrl][INFO] Max num steps: 42, rb length 120\n",
            "2024-11-16 15:37:20,189 [torchrl][INFO] Max num steps: 42, rb length 120\n",
            "2024-11-16 15:37:20,798 [torchrl][INFO] Max num steps: 42, rb length 120\n",
            "2024-11-16 15:37:21,301 [torchrl][INFO] Max num steps: 42, rb length 120\n",
            "2024-11-16 15:37:23,098 [torchrl][INFO] Max num steps: 42, rb length 120\n",
            "2024-11-16 15:37:24,278 [torchrl][INFO] Max num steps: 42, rb length 120\n",
            "2024-11-16 15:37:25,262 [torchrl][INFO] Max num steps: 42, rb length 120\n",
            "2024-11-16 15:37:26,389 [torchrl][INFO] Max num steps: 42, rb length 120\n",
            "2024-11-16 15:37:28,238 [torchrl][INFO] Max num steps: 42, rb length 128\n",
            "2024-11-16 15:37:29,639 [torchrl][INFO] Max num steps: 42, rb length 128\n",
            "2024-11-16 15:37:31,025 [torchrl][INFO] Max num steps: 42, rb length 128\n",
            "2024-11-16 15:37:32,215 [torchrl][INFO] Max num steps: 42, rb length 128\n",
            "2024-11-16 15:37:33,060 [torchrl][INFO] Max num steps: 42, rb length 128\n",
            "2024-11-16 15:37:33,601 [torchrl][INFO] Max num steps: 42, rb length 128\n",
            "2024-11-16 15:37:33,981 [torchrl][INFO] Max num steps: 42, rb length 128\n",
            "2024-11-16 15:37:34,280 [torchrl][INFO] Max num steps: 42, rb length 128\n",
            "2024-11-16 15:37:34,630 [torchrl][INFO] Max num steps: 42, rb length 128\n",
            "2024-11-16 15:37:34,936 [torchrl][INFO] Max num steps: 42, rb length 128\n",
            "2024-11-16 15:37:35,319 [torchrl][INFO] Max num steps: 42, rb length 136\n",
            "2024-11-16 15:37:35,614 [torchrl][INFO] Max num steps: 42, rb length 136\n",
            "2024-11-16 15:37:35,976 [torchrl][INFO] Max num steps: 42, rb length 136\n",
            "2024-11-16 15:37:36,274 [torchrl][INFO] Max num steps: 42, rb length 136\n",
            "2024-11-16 15:37:36,605 [torchrl][INFO] Max num steps: 42, rb length 136\n",
            "2024-11-16 15:37:36,911 [torchrl][INFO] Max num steps: 42, rb length 136\n",
            "2024-11-16 15:37:37,235 [torchrl][INFO] Max num steps: 42, rb length 136\n",
            "2024-11-16 15:37:37,534 [torchrl][INFO] Max num steps: 42, rb length 136\n",
            "2024-11-16 15:37:37,850 [torchrl][INFO] Max num steps: 42, rb length 136\n",
            "2024-11-16 15:37:38,274 [torchrl][INFO] Max num steps: 42, rb length 136\n",
            "2024-11-16 15:37:38,876 [torchrl][INFO] Max num steps: 42, rb length 144\n",
            "2024-11-16 15:37:39,521 [torchrl][INFO] Max num steps: 42, rb length 144\n",
            "2024-11-16 15:37:40,169 [torchrl][INFO] Max num steps: 42, rb length 144\n",
            "2024-11-16 15:37:40,764 [torchrl][INFO] Max num steps: 42, rb length 144\n",
            "2024-11-16 15:37:41,238 [torchrl][INFO] Max num steps: 42, rb length 144\n",
            "2024-11-16 15:37:41,757 [torchrl][INFO] Max num steps: 42, rb length 144\n",
            "2024-11-16 15:37:42,698 [torchrl][INFO] Max num steps: 42, rb length 144\n",
            "2024-11-16 15:37:43,688 [torchrl][INFO] Max num steps: 42, rb length 144\n",
            "2024-11-16 15:37:44,724 [torchrl][INFO] Max num steps: 42, rb length 144\n",
            "2024-11-16 15:37:45,865 [torchrl][INFO] Max num steps: 42, rb length 144\n",
            "2024-11-16 15:37:46,516 [torchrl][INFO] Max num steps: 42, rb length 152\n",
            "2024-11-16 15:37:47,150 [torchrl][INFO] Max num steps: 42, rb length 152\n",
            "2024-11-16 15:37:47,753 [torchrl][INFO] Max num steps: 42, rb length 152\n",
            "2024-11-16 15:37:48,346 [torchrl][INFO] Max num steps: 42, rb length 152\n",
            "2024-11-16 15:37:48,942 [torchrl][INFO] Max num steps: 42, rb length 152\n",
            "2024-11-16 15:37:49,565 [torchrl][INFO] Max num steps: 42, rb length 152\n",
            "2024-11-16 15:37:50,117 [torchrl][INFO] Max num steps: 42, rb length 152\n",
            "2024-11-16 15:37:50,585 [torchrl][INFO] Max num steps: 42, rb length 152\n",
            "2024-11-16 15:37:51,158 [torchrl][INFO] Max num steps: 42, rb length 152\n",
            "2024-11-16 15:37:51,504 [torchrl][INFO] Max num steps: 42, rb length 152\n",
            "2024-11-16 15:37:51,861 [torchrl][INFO] Max num steps: 42, rb length 160\n",
            "2024-11-16 15:37:52,178 [torchrl][INFO] Max num steps: 42, rb length 160\n",
            "2024-11-16 15:37:52,551 [torchrl][INFO] Max num steps: 42, rb length 160\n",
            "2024-11-16 15:37:52,840 [torchrl][INFO] Max num steps: 42, rb length 160\n",
            "2024-11-16 15:37:53,176 [torchrl][INFO] Max num steps: 42, rb length 160\n",
            "2024-11-16 15:37:53,467 [torchrl][INFO] Max num steps: 42, rb length 160\n",
            "2024-11-16 15:37:53,770 [torchrl][INFO] Max num steps: 42, rb length 160\n",
            "2024-11-16 15:37:54,067 [torchrl][INFO] Max num steps: 42, rb length 160\n",
            "2024-11-16 15:37:54,361 [torchrl][INFO] Max num steps: 42, rb length 160\n",
            "2024-11-16 15:37:54,666 [torchrl][INFO] Max num steps: 42, rb length 160\n",
            "2024-11-16 15:37:59,065 [torchrl][INFO] Max num steps: 42, rb length 176\n",
            "2024-11-16 15:37:59,365 [torchrl][INFO] Max num steps: 42, rb length 176\n",
            "2024-11-16 15:37:59,697 [torchrl][INFO] Max num steps: 42, rb length 176\n",
            "2024-11-16 15:37:59,996 [torchrl][INFO] Max num steps: 42, rb length 176\n",
            "2024-11-16 15:38:00,288 [torchrl][INFO] Max num steps: 42, rb length 176\n",
            "2024-11-16 15:38:00,603 [torchrl][INFO] Max num steps: 42, rb length 176\n",
            "2024-11-16 15:38:00,904 [torchrl][INFO] Max num steps: 42, rb length 176\n",
            "2024-11-16 15:38:01,199 [torchrl][INFO] Max num steps: 42, rb length 176\n",
            "2024-11-16 15:38:01,490 [torchrl][INFO] Max num steps: 42, rb length 176\n",
            "2024-11-16 15:38:01,785 [torchrl][INFO] Max num steps: 42, rb length 176\n",
            "2024-11-16 15:38:02,144 [torchrl][INFO] Max num steps: 42, rb length 184\n",
            "2024-11-16 15:38:02,436 [torchrl][INFO] Max num steps: 42, rb length 184\n",
            "2024-11-16 15:38:02,729 [torchrl][INFO] Max num steps: 42, rb length 184\n",
            "2024-11-16 15:38:03,030 [torchrl][INFO] Max num steps: 42, rb length 184\n",
            "2024-11-16 15:38:03,328 [torchrl][INFO] Max num steps: 42, rb length 184\n",
            "2024-11-16 15:38:03,619 [torchrl][INFO] Max num steps: 42, rb length 184\n",
            "2024-11-16 15:38:03,921 [torchrl][INFO] Max num steps: 42, rb length 184\n",
            "2024-11-16 15:38:04,216 [torchrl][INFO] Max num steps: 42, rb length 184\n",
            "2024-11-16 15:38:04,507 [torchrl][INFO] Max num steps: 42, rb length 184\n",
            "2024-11-16 15:38:04,802 [torchrl][INFO] Max num steps: 42, rb length 184\n",
            "2024-11-16 15:38:05,158 [torchrl][INFO] Max num steps: 42, rb length 192\n",
            "2024-11-16 15:38:05,454 [torchrl][INFO] Max num steps: 42, rb length 192\n",
            "2024-11-16 15:38:05,746 [torchrl][INFO] Max num steps: 42, rb length 192\n",
            "2024-11-16 15:38:06,057 [torchrl][INFO] Max num steps: 42, rb length 192\n",
            "2024-11-16 15:38:06,349 [torchrl][INFO] Max num steps: 42, rb length 192\n",
            "2024-11-16 15:38:06,644 [torchrl][INFO] Max num steps: 42, rb length 192\n",
            "2024-11-16 15:38:06,934 [torchrl][INFO] Max num steps: 42, rb length 192\n",
            "2024-11-16 15:38:07,238 [torchrl][INFO] Max num steps: 42, rb length 192\n",
            "2024-11-16 15:38:07,529 [torchrl][INFO] Max num steps: 42, rb length 192\n",
            "2024-11-16 15:38:07,827 [torchrl][INFO] Max num steps: 42, rb length 192\n",
            "2024-11-16 15:38:08,192 [torchrl][INFO] Max num steps: 42, rb length 200\n",
            "2024-11-16 15:38:08,485 [torchrl][INFO] Max num steps: 42, rb length 200\n",
            "2024-11-16 15:38:08,781 [torchrl][INFO] Max num steps: 42, rb length 200\n",
            "2024-11-16 15:38:09,132 [torchrl][INFO] Max num steps: 42, rb length 200\n",
            "2024-11-16 15:38:09,563 [torchrl][INFO] Max num steps: 42, rb length 200\n",
            "2024-11-16 15:38:10,011 [torchrl][INFO] Max num steps: 42, rb length 200\n",
            "2024-11-16 15:38:10,465 [torchrl][INFO] Max num steps: 42, rb length 200\n",
            "2024-11-16 15:38:10,893 [torchrl][INFO] Max num steps: 42, rb length 200\n",
            "2024-11-16 15:38:11,340 [torchrl][INFO] Max num steps: 42, rb length 200\n",
            "2024-11-16 15:38:11,784 [torchrl][INFO] Max num steps: 42, rb length 200\n",
            "2024-11-16 15:38:12,261 [torchrl][INFO] Max num steps: 42, rb length 208\n",
            "2024-11-16 15:38:12,557 [torchrl][INFO] Max num steps: 42, rb length 208\n",
            "2024-11-16 15:38:12,848 [torchrl][INFO] Max num steps: 42, rb length 208\n",
            "2024-11-16 15:38:13,151 [torchrl][INFO] Max num steps: 42, rb length 208\n",
            "2024-11-16 15:38:13,451 [torchrl][INFO] Max num steps: 42, rb length 208\n",
            "2024-11-16 15:38:13,747 [torchrl][INFO] Max num steps: 42, rb length 208\n",
            "2024-11-16 15:38:14,042 [torchrl][INFO] Max num steps: 42, rb length 208\n",
            "2024-11-16 15:38:14,349 [torchrl][INFO] Max num steps: 42, rb length 208\n",
            "2024-11-16 15:38:14,645 [torchrl][INFO] Max num steps: 42, rb length 208\n",
            "2024-11-16 15:38:14,936 [torchrl][INFO] Max num steps: 42, rb length 208\n",
            "2024-11-16 15:38:15,304 [torchrl][INFO] Max num steps: 42, rb length 216\n",
            "2024-11-16 15:38:15,600 [torchrl][INFO] Max num steps: 42, rb length 216\n",
            "2024-11-16 15:38:15,894 [torchrl][INFO] Max num steps: 42, rb length 216\n",
            "2024-11-16 15:38:16,192 [torchrl][INFO] Max num steps: 42, rb length 216\n",
            "2024-11-16 15:38:16,497 [torchrl][INFO] Max num steps: 42, rb length 216\n",
            "2024-11-16 15:38:16,792 [torchrl][INFO] Max num steps: 42, rb length 216\n",
            "2024-11-16 15:38:17,085 [torchrl][INFO] Max num steps: 42, rb length 216\n",
            "2024-11-16 15:38:17,388 [torchrl][INFO] Max num steps: 42, rb length 216\n",
            "2024-11-16 15:38:17,683 [torchrl][INFO] Max num steps: 42, rb length 216\n",
            "2024-11-16 15:38:17,973 [torchrl][INFO] Max num steps: 42, rb length 216\n",
            "2024-11-16 15:38:18,350 [torchrl][INFO] Max num steps: 42, rb length 224\n",
            "2024-11-16 15:38:18,650 [torchrl][INFO] Max num steps: 42, rb length 224\n",
            "2024-11-16 15:38:18,941 [torchrl][INFO] Max num steps: 42, rb length 224\n",
            "2024-11-16 15:38:19,236 [torchrl][INFO] Max num steps: 42, rb length 224\n",
            "2024-11-16 15:38:19,541 [torchrl][INFO] Max num steps: 42, rb length 224\n",
            "2024-11-16 15:38:19,835 [torchrl][INFO] Max num steps: 42, rb length 224\n",
            "2024-11-16 15:38:20,135 [torchrl][INFO] Max num steps: 42, rb length 224\n",
            "2024-11-16 15:38:20,436 [torchrl][INFO] Max num steps: 42, rb length 224\n",
            "2024-11-16 15:38:20,733 [torchrl][INFO] Max num steps: 42, rb length 224\n",
            "2024-11-16 15:38:21,026 [torchrl][INFO] Max num steps: 42, rb length 224\n",
            "2024-11-16 15:38:21,386 [torchrl][INFO] Max num steps: 42, rb length 232\n",
            "2024-11-16 15:38:21,686 [torchrl][INFO] Max num steps: 42, rb length 232\n",
            "2024-11-16 15:38:21,978 [torchrl][INFO] Max num steps: 42, rb length 232\n",
            "2024-11-16 15:38:22,352 [torchrl][INFO] Max num steps: 42, rb length 232\n",
            "2024-11-16 15:38:22,811 [torchrl][INFO] Max num steps: 42, rb length 232\n",
            "2024-11-16 15:38:23,269 [torchrl][INFO] Max num steps: 42, rb length 232\n",
            "2024-11-16 15:38:23,731 [torchrl][INFO] Max num steps: 42, rb length 232\n",
            "2024-11-16 15:38:24,181 [torchrl][INFO] Max num steps: 42, rb length 232\n",
            "2024-11-16 15:38:24,633 [torchrl][INFO] Max num steps: 42, rb length 232\n",
            "2024-11-16 15:38:25,082 [torchrl][INFO] Max num steps: 42, rb length 232\n",
            "2024-11-16 15:38:25,459 [torchrl][INFO] Max num steps: 42, rb length 240\n",
            "2024-11-16 15:38:25,761 [torchrl][INFO] Max num steps: 42, rb length 240\n",
            "2024-11-16 15:38:26,056 [torchrl][INFO] Max num steps: 42, rb length 240\n",
            "2024-11-16 15:38:26,353 [torchrl][INFO] Max num steps: 42, rb length 240\n",
            "2024-11-16 15:38:26,645 [torchrl][INFO] Max num steps: 42, rb length 240\n",
            "2024-11-16 15:38:26,952 [torchrl][INFO] Max num steps: 42, rb length 240\n",
            "2024-11-16 15:38:27,245 [torchrl][INFO] Max num steps: 42, rb length 240\n",
            "2024-11-16 15:38:27,537 [torchrl][INFO] Max num steps: 42, rb length 240\n",
            "2024-11-16 15:38:27,841 [torchrl][INFO] Max num steps: 42, rb length 240\n",
            "2024-11-16 15:38:28,135 [torchrl][INFO] Max num steps: 42, rb length 240\n",
            "2024-11-16 15:38:31,476 [torchrl][INFO] Max num steps: 51, rb length 256\n",
            "2024-11-16 15:38:31,772 [torchrl][INFO] Max num steps: 51, rb length 256\n",
            "2024-11-16 15:38:32,084 [torchrl][INFO] Max num steps: 51, rb length 256\n",
            "2024-11-16 15:38:32,376 [torchrl][INFO] Max num steps: 51, rb length 256\n",
            "2024-11-16 15:38:32,670 [torchrl][INFO] Max num steps: 51, rb length 256\n",
            "2024-11-16 15:38:32,972 [torchrl][INFO] Max num steps: 51, rb length 256\n",
            "2024-11-16 15:38:33,267 [torchrl][INFO] Max num steps: 51, rb length 256\n",
            "2024-11-16 15:38:33,557 [torchrl][INFO] Max num steps: 51, rb length 256\n",
            "2024-11-16 15:38:33,852 [torchrl][INFO] Max num steps: 51, rb length 256\n",
            "2024-11-16 15:38:34,156 [torchrl][INFO] Max num steps: 51, rb length 256\n",
            "2024-11-16 15:38:34,160 [torchrl][INFO] solved after 1600 steps, 60 episodes and in 89.777902841568s.\n"
          ]
        }
      ],
      "source": [
        "total_count = 0\n",
        "total_episodes = 0\n",
        "t0 = time.time()\n",
        "for i, data in enumerate(collector):\n",
        "    # Write data in replay buffer\n",
        "    rb.extend(data)\n",
        "    max_length = rb[:][\"next\", \"step_count\"].max()\n",
        "    if len(rb) > init_rand_steps:\n",
        "        # Optim loop (we do several optim steps\n",
        "        # per batch collected for efficiency)\n",
        "        for _ in range(optim_steps):\n",
        "            sample = rb.sample(128)\n",
        "            loss_vals = loss(sample)\n",
        "            loss_vals[\"loss\"].backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "            # Update exploration factor\n",
        "            exploration_module.step(data.numel())\n",
        "            # Update target params\n",
        "            updater.step()\n",
        "            if i % 10:\n",
        "                torchrl_logger.info(f\"Max num steps: {max_length}, rb length {len(rb)}\")\n",
        "            total_count += data.numel()\n",
        "            total_episodes += data[\"next\", \"done\"].sum()\n",
        "    if max_length > 50:\n",
        "        break\n",
        "\n",
        "t1 = time.time()\n",
        "\n",
        "torchrl_logger.info(\n",
        "    f\"solved after {total_count} steps, {total_episodes} episodes and in {t1-t0}s.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftzr00n_0uCn"
      },
      "source": [
        "## Rendering\n",
        "\n",
        "Finally, we run the environment for as many steps as we can and save the\n",
        "video locally (notice that we are not exploring).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install av"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69E5fliDm7gm",
        "outputId": "eb71bb2c-c61c-4229-80ad-b2a6148f2d68"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: av in /usr/local/lib/python3.10/dist-packages (13.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "On-ga3ut0uCn"
      },
      "outputs": [],
      "source": [
        "record_env.rollout(max_steps=1000, policy=policy)\n",
        "video_recorder.dump()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIVCzUfX0uCo"
      },
      "source": [
        "This is what your rendered CartPole video will look like after a full\n",
        "training loop:\n",
        "\n",
        ".. figure:: /_static/img/cartpole.gif\n",
        "\n",
        "This concludes our series of \"Getting started with TorchRL\" tutorials!\n",
        "Feel free to share feedback about it on GitHub.\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}