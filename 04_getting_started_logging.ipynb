{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AiProcess/torch_deep_rl/blob/main/04_getting_started_logging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhJwSAZ9ByIk"
      },
      "source": [
        "\n",
        "# Get started with logging\n",
        "\n",
        "**Author**: [Vincent Moens](https://github.com/vmoens)\n",
        "\n",
        "\n",
        "<div class=\"alert alert-info\"><h4>Note</h4><p>To run this tutorial in a notebook, add an installation cell\n",
        "  at the beginning containing:\n",
        "\n",
        "```\n",
        "!pip install tensordict\n",
        "!pip install torchrl</p></div>\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensordict\n",
        "!pip install torchrl"
      ],
      "metadata": {
        "id": "CyvG0_IuSp9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxNbvX_XByIp"
      },
      "source": [
        "The final chapter of this series before we orchestrate everything in a\n",
        "training script is to learn about logging.\n",
        "\n",
        "## Loggers\n",
        "\n",
        "Logging is crucial for reporting your results to the outside world and for\n",
        "you to check that your algorithm is learning properly. TorchRL has several\n",
        "loggers that interface with custom backends such as\n",
        "wandb (:class:`~torchrl.record.loggers.wandb.WandbLogger`),\n",
        "tensorboard (:class:`~torchrl.record.loggers.tensorboard.TensorBoardLogger`) or a lightweight and\n",
        "portable CSV logger (:class:`~torchrl.record.loggers.csv.CSVLogger`) that you can use\n",
        "pretty much everywhere.\n",
        "\n",
        "Loggers are located in the ``torchrl.record`` module and the various classes\n",
        "can be found in the `API reference <ref_loggers>`.\n",
        "\n",
        "We tried to keep the loggers APIs as similar as we could, given the\n",
        "differences in the underlying backends. While execution of the loggers will\n",
        "mostly be interchangeable, their instantiation can differ.\n",
        "\n",
        "Usually, building a logger requires\n",
        "at least an experiment name and possibly a logging directory and other\n",
        "hyperparameters.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "stPJMkW0ByIq"
      },
      "outputs": [],
      "source": [
        "from torchrl.record import CSVLogger\n",
        "\n",
        "logger = CSVLogger(exp_name=\"my_exp\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UVp-Ui4ByIs"
      },
      "source": [
        "Once the logger is instantiated, the only thing left to do is call the\n",
        "logging methods! For example, :meth:`~torchrl.record.CSVLogger.log_scalar`\n",
        "is used in several places across the training examples to log values such as\n",
        "reward, loss value or time elapsed for executing a piece of code.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QYKZYh03ByIt"
      },
      "outputs": [],
      "source": [
        "logger.log_scalar(\"my_scalar\", 0.4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65CbxKEeByIu"
      },
      "source": [
        "## Recording videos\n",
        "\n",
        "Finally, it can come in handy to record videos of a simulator. Some\n",
        "environments (e.g., Atari games) are already rendered as images whereas\n",
        "others require you to create them as such. Fortunately, in most common cases,\n",
        "rendering and recording videos isn't too difficult.\n",
        "\n",
        "Let's first see how we can create a Gym environment that outputs images\n",
        "alongside its observations. :class:`~torchrl.envs.GymEnv` accept two keywords\n",
        "for this purpose:\n",
        "- ``from_pixels=True`` will make the env ``step`` function\n",
        "write a ``\"pixels\"`` entry containing the images corresponding to your\n",
        "observations, and\n",
        "\n",
        "- ``pixels_only=False`` will indicate that you want the\n",
        "observations to be returned as well.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sOCyvTObByIu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e9cb366-af21-4b11-e090-a762601b30dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorDict(\n",
            "    fields={\n",
            "        action: Tensor(shape=torch.Size([3, 2]), device=cpu, dtype=torch.int64, is_shared=False),\n",
            "        done: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        next: TensorDict(\n",
            "            fields={\n",
            "                done: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                pixels: Tensor(shape=torch.Size([3, 400, 600, 3]), device=cpu, dtype=torch.uint8, is_shared=False),\n",
            "                reward: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "                terminated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "                truncated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "            batch_size=torch.Size([3]),\n",
            "            device=None,\n",
            "            is_shared=False),\n",
            "        observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "        pixels: Tensor(shape=torch.Size([3, 400, 600, 3]), device=cpu, dtype=torch.uint8, is_shared=False),\n",
            "        terminated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
            "        truncated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
            "    batch_size=torch.Size([3]),\n",
            "    device=None,\n",
            "    is_shared=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "from torchrl.envs import GymEnv\n",
        "\n",
        "env = GymEnv(\"CartPole-v1\", from_pixels=True, pixels_only=False)\n",
        "\n",
        "print(env.rollout(max_steps=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPGcnlB7ByIv"
      },
      "source": [
        "We now have built an environment that renders images with its observations.\n",
        "To record videos, we will need to combine that environment with a recorder\n",
        "and the logger (the logger providing the backend to save the video).\n",
        "This will happen within a transformed environment, like the one we saw in\n",
        "the `first tutorial <gs_env_ted>`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "rQdJg8qVByIv"
      },
      "outputs": [],
      "source": [
        "from torchrl.envs import TransformedEnv\n",
        "from torchrl.record import VideoRecorder\n",
        "\n",
        "recorder = VideoRecorder(logger, tag=\"my_video\")\n",
        "record_env = TransformedEnv(env, recorder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeUo6PT7ByIw"
      },
      "source": [
        "When running this environment, all the ``\"pixels\"`` entries will be saved in\n",
        "a local buffer (i.e. RAM) and dumped in a video on demand (to prevent excessive\n",
        "RAM usage, you are advised to call this method whenever appropriate!):\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kv9ouRxxByIx"
      },
      "outputs": [],
      "source": [
        "rollout = record_env.rollout(max_steps=3)\n",
        "# Uncomment this line to save the video on disk:\n",
        "recorder.dump()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzCLOGsGByIx"
      },
      "source": [
        "In this specific case, the video format can be chosen when instantiating\n",
        "the CSVLogger.\n",
        "\n",
        "(If you want to customise how your video is recorded, have a look at `our knowledge base <ref_knowledge_base>`.)\n",
        "\n",
        "This is all we wanted to cover in the getting started tutorial.\n",
        "You should now be ready to code your\n",
        "`first training loop with TorchRL <gs_first_training>`!\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}