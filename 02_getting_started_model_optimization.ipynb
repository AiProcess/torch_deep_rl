{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AiProcess/torch_deep_rl/blob/main/02_getting_started_model_optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfTzhebsz6co"
      },
      "source": [
        "\n",
        "# Getting started with model optimization\n",
        "\n",
        "**Author**: [Vincent Moens](https://github.com/vmoens)\n",
        "\n",
        "\n",
        "<div class=\"alert alert-info\"><h4>Note</h4><p>To run this tutorial in a notebook, add an installation cell\n",
        "  at the beginning containing:\n",
        "\n",
        "```\n",
        "!pip install tensordict\n",
        "!pip install torchrl</p></div>\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensordict\n",
        "!pip install torchrl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njqWot6VGwG7",
        "outputId": "48c58376-e5e9-4d75-83d6-e59eee90ac14"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensordict\n",
            "  Downloading tensordict-0.5.0-cp310-cp310-manylinux1_x86_64.whl.metadata (22 kB)\n",
            "Collecting torch>=2.4.0 (from tensordict)\n",
            "  Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensordict) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from tensordict) (2.2.1)\n",
            "Collecting orjson (from tensordict)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->tensordict) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.4.0->tensordict)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.4.0->tensordict)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.4.0->tensordict)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.0->tensordict)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.4.0->tensordict)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.4.0->tensordict)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.4.0->tensordict)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.4.0->tensordict)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.4.0->tensordict)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.4.0->tensordict)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.4.0->tensordict)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.0.0 (from torch>=2.4.0->tensordict)\n",
            "  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.4.0->tensordict)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.4.0->tensordict) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.4.0->tensordict) (1.3.0)\n",
            "Downloading tensordict-0.5.0-cp310-cp310-manylinux1_x86_64.whl (336 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.1/336.1 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl (797.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: triton, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, tensordict\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.3.1\n",
            "    Uninstalling triton-2.3.1:\n",
            "      Successfully uninstalled triton-2.3.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.3.1+cu121\n",
            "    Uninstalling torch-2.3.1+cu121:\n",
            "      Successfully uninstalled torch-2.3.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.3.1+cu121 requires torch==2.3.1, but you have torch 2.4.0 which is incompatible.\n",
            "torchvision 0.18.1+cu121 requires torch==2.3.1, but you have torch 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 orjson-3.10.7 tensordict-0.5.0 torch-2.4.0 triton-3.0.0\n",
            "Collecting torchrl\n",
            "  Downloading torchrl-0.5.0-cp310-cp310-manylinux1_x86_64.whl.metadata (33 kB)\n",
            "Requirement already satisfied: torch>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from torchrl) (2.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchrl) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchrl) (24.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from torchrl) (2.2.1)\n",
            "Requirement already satisfied: tensordict>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from torchrl) (0.5.0)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.10/dist-packages (from tensordict>=0.5.0->torchrl) (3.10.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.3.0->torchrl) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.3.0->torchrl) (12.6.20)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.3.0->torchrl) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.3.0->torchrl) (1.3.0)\n",
            "Downloading torchrl-0.5.0-cp310-cp310-manylinux1_x86_64.whl (987 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m988.0/988.0 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchrl\n",
            "Successfully installed torchrl-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTN1xuNDz6cu"
      },
      "source": [
        "In TorchRL, we try to treat optimization as it is custom to do in PyTorch,\n",
        "using dedicated loss modules which are designed with the sole purpose of\n",
        "optimizing the model. This approach efficiently decouples the execution of\n",
        "the policy from its training and allows us to design training loops that are\n",
        "similar to what can be found in traditional supervised learning examples.\n",
        "\n",
        "The typical training loop therefore looks like this:\n",
        "\n",
        "```\n",
        "  >>> for i in range(n_collections):\n",
        "  ...     data = get_next_batch(env, policy)\n",
        "  ...     for j in range(n_optim):\n",
        "  ...         loss = loss_fn(data)\n",
        "  ...         loss.backward()\n",
        "  ...         optim.step()\n",
        "```\n",
        "\n",
        "In this concise tutorial, you will receive a brief overview of the loss modules. Due to the typically\n",
        "straightforward nature of the API for basic usage, this tutorial will be kept brief.\n",
        "\n",
        "## RL objective functions\n",
        "\n",
        "In RL, innovation typically involves the exploration of novel methods\n",
        "for optimizing a policy (i.e., new algorithms), rather than focusing\n",
        "on new architectures, as seen in other domains. Within TorchRL,\n",
        "these algorithms are encapsulated within loss modules. A loss\n",
        "module orchestrates the various components of your algorithm and\n",
        "yields a set of loss values that can be backpropagated\n",
        "through to train the corresponding components.\n",
        "\n",
        "In this tutorial, we will take a popular\n",
        "off-policy algorithm as an example,\n",
        "[DDPG](https://arxiv.org/abs/1509.02971).\n",
        "\n",
        "To build a loss module, the only thing one needs is a set of networks\n",
        "defined as :class:`~tensordict.nn.TensorDictModule`s. Most of the time, one\n",
        "of these modules will be the policy. Other auxiliary networks such as\n",
        "Q-Value networks or critics of some kind may be needed as well. Let's see\n",
        "what this looks like in practice: DDPG requires a deterministic\n",
        "map from the observation space to the action space as well as a value\n",
        "network that predicts the value of a state-action pair. The DDPG loss will\n",
        "attempt to find the policy parameters that output actions that maximize the\n",
        "value for a given state.\n",
        "\n",
        "To build the loss, we need both the actor and value networks.\n",
        "If they are built according to DDPG's expectations, it is all\n",
        "we need to get a trainable loss module:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OoS4vso6z6cw"
      },
      "outputs": [],
      "source": [
        "from torchrl.envs import GymEnv\n",
        "\n",
        "env = GymEnv(\"Pendulum-v1\")\n",
        "\n",
        "from torchrl.modules import Actor, MLP, ValueOperator\n",
        "from torchrl.objectives import DDPGLoss\n",
        "\n",
        "n_obs = env.observation_spec[\"observation\"].shape[-1]\n",
        "n_act = env.action_spec.shape[-1]\n",
        "actor = Actor(MLP(in_features=n_obs, out_features=n_act, num_cells=[32, 32]))\n",
        "value_net = ValueOperator(\n",
        "    MLP(in_features=n_obs + n_act, out_features=1, num_cells=[32, 32]),\n",
        "    in_keys=[\"observation\", \"action\"],\n",
        ")\n",
        "\n",
        "ddpg_loss = DDPGLoss(actor_network=actor, value_network=value_net)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DDPG Loss"
      ],
      "metadata": {
        "id": "HqWJn7a_0_aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ddpg_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VI3RxlgB0eLh",
        "outputId": "bd12477a-4277-4806-a60b-2db72393e3cd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DDPGLoss(\n",
              "  (actor_network_params): TensorDictParams(params=TensorDict(\n",
              "      fields={\n",
              "          module: TensorDict(\n",
              "              fields={\n",
              "                  0: TensorDict(\n",
              "                      fields={\n",
              "                          bias: Parameter(shape=torch.Size([32]), device=cpu, dtype=torch.float32, is_shared=False),\n",
              "                          weight: Parameter(shape=torch.Size([32, 3]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
              "                      batch_size=torch.Size([]),\n",
              "                      device=None,\n",
              "                      is_shared=False),\n",
              "                  2: TensorDict(\n",
              "                      fields={\n",
              "                          bias: Parameter(shape=torch.Size([32]), device=cpu, dtype=torch.float32, is_shared=False),\n",
              "                          weight: Parameter(shape=torch.Size([32, 32]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
              "                      batch_size=torch.Size([]),\n",
              "                      device=None,\n",
              "                      is_shared=False),\n",
              "                  4: TensorDict(\n",
              "                      fields={\n",
              "                          bias: Parameter(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
              "                          weight: Parameter(shape=torch.Size([1, 32]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
              "                      batch_size=torch.Size([]),\n",
              "                      device=None,\n",
              "                      is_shared=False)},\n",
              "              batch_size=torch.Size([]),\n",
              "              device=None,\n",
              "              is_shared=False)},\n",
              "      batch_size=torch.Size([]),\n",
              "      device=None,\n",
              "      is_shared=False))\n",
              "  (value_network_params): TensorDictParams(params=TensorDict(\n",
              "      fields={\n",
              "          module: TensorDict(\n",
              "              fields={\n",
              "                  0: TensorDict(\n",
              "                      fields={\n",
              "                          bias: Parameter(shape=torch.Size([32]), device=cpu, dtype=torch.float32, is_shared=False),\n",
              "                          weight: Parameter(shape=torch.Size([32, 4]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
              "                      batch_size=torch.Size([]),\n",
              "                      device=None,\n",
              "                      is_shared=False),\n",
              "                  2: TensorDict(\n",
              "                      fields={\n",
              "                          bias: Parameter(shape=torch.Size([32]), device=cpu, dtype=torch.float32, is_shared=False),\n",
              "                          weight: Parameter(shape=torch.Size([32, 32]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
              "                      batch_size=torch.Size([]),\n",
              "                      device=None,\n",
              "                      is_shared=False),\n",
              "                  4: TensorDict(\n",
              "                      fields={\n",
              "                          bias: Parameter(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
              "                          weight: Parameter(shape=torch.Size([1, 32]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
              "                      batch_size=torch.Size([]),\n",
              "                      device=None,\n",
              "                      is_shared=False)},\n",
              "              batch_size=torch.Size([]),\n",
              "              device=None,\n",
              "              is_shared=False)},\n",
              "      batch_size=torch.Size([]),\n",
              "      device=None,\n",
              "      is_shared=False))\n",
              "  (target_value_network_params): TensorDictParams(params=TensorDict(\n",
              "      fields={\n",
              "          module: TensorDict(\n",
              "              fields={\n",
              "                  0: TensorDict(\n",
              "                      fields={\n",
              "                          bias: Parameter(shape=torch.Size([32]), device=cpu, dtype=torch.float32, is_shared=False),\n",
              "                          weight: Parameter(shape=torch.Size([32, 4]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
              "                      batch_size=torch.Size([]),\n",
              "                      device=None,\n",
              "                      is_shared=False),\n",
              "                  2: TensorDict(\n",
              "                      fields={\n",
              "                          bias: Parameter(shape=torch.Size([32]), device=cpu, dtype=torch.float32, is_shared=False),\n",
              "                          weight: Parameter(shape=torch.Size([32, 32]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
              "                      batch_size=torch.Size([]),\n",
              "                      device=None,\n",
              "                      is_shared=False),\n",
              "                  4: TensorDict(\n",
              "                      fields={\n",
              "                          bias: Parameter(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
              "                          weight: Parameter(shape=torch.Size([1, 32]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
              "                      batch_size=torch.Size([]),\n",
              "                      device=None,\n",
              "                      is_shared=False)},\n",
              "              batch_size=torch.Size([]),\n",
              "              device=None,\n",
              "              is_shared=False)},\n",
              "      batch_size=torch.Size([]),\n",
              "      device=None,\n",
              "      is_shared=False))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heGC-N__z6cz"
      },
      "source": [
        "And that is it! Our loss module can now be run with data coming from the\n",
        "environment (we omit exploration, storage and other features to focus on\n",
        "the loss functionality):\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "S3U_tWvJz6c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f20773b8-0386-4da5-dcf1-e4945149d836"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorDict(\n",
            "    fields={\n",
            "        loss_actor: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "        loss_value: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "        pred_value: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "        pred_value_max: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "        target_value: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "        target_value_max: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
            "        td_error: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
            "    batch_size=torch.Size([]),\n",
            "    device=None,\n",
            "    is_shared=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchrl/objectives/common.py:29: UserWarning: No target network updater has been associated with this loss module, but target parameters have been found. While this is supported, it is expected that the target network updates will be manually performed. You can deactivate this warning by turning the RL_WARNINGS env variable to False.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchrl/objectives/common.py:420: UserWarning: No target network updater has been associated with this loss module, but target parameters have been found. While this is supported, it is expected that the target network updates will be manually performed. You can deactivate this warning by turning the RL_WARNINGS env variable to False.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "rollout = env.rollout(max_steps=100, policy=actor)\n",
        "loss_vals = ddpg_loss(rollout)\n",
        "print(loss_vals)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRIMKd-Dz6c1"
      },
      "source": [
        "## LossModule's output\n",
        "\n",
        "As you can see, the value we received from the loss isn't a single scalar\n",
        "but a dictionary containing multiple losses.\n",
        "\n",
        "The reason is simple: because more than one network may be trained at a time,\n",
        "and since some users may wish to separate the optimization of each module\n",
        "in distinct steps, TorchRL's objectives will return dictionaries containing\n",
        "the various loss components.\n",
        "\n",
        "This format also allows us to pass metadata along with the loss values. In\n",
        "general, we make sure that only the loss values are differentiable such that\n",
        "you can simply sum over the values of the dictionary to obtain the total\n",
        "loss. If you want to make sure you're fully in control of what is happening,\n",
        "you can sum over only the entries which keys start with the ``\"loss_\"`` prefix:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7A0bo5QEz6c1"
      },
      "outputs": [],
      "source": [
        "total_loss = 0\n",
        "for key, val in loss_vals.items():\n",
        "    if key.startswith(\"loss_\"):\n",
        "        total_loss += val"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjWQZLOe1Y5u",
        "outputId": "fe6d453b-20d1-431b-fcc0-4fc60cc36987"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(44.0838, grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQAooB9kz6c2"
      },
      "source": [
        "## Training a LossModule\n",
        "\n",
        "Given all this, training the modules is not so different from what would be\n",
        "done in any other training loop. Because it wraps the modules,\n",
        "the easiest way to get the list of trainable parameters is to query\n",
        "the :meth:`~torchrl.objectives.LossModule.parameters` method.\n",
        "\n",
        "We'll need an optimizer (or one optimizer\n",
        "per module if that is your choice).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ddpg_loss.parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiJqCjV1OYcS",
        "outputId": "58f30231-bc88-4d63-8889-2b3d3fdaa595"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object LossModule.parameters at 0x7afb37220f20>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xHYiTDlez6c2"
      },
      "outputs": [],
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "optim = Adam(ddpg_loss.parameters())\n",
        "total_loss.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sM3GWI6Az6c3"
      },
      "source": [
        "The following items will typically be\n",
        "found in your training loop:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4_twddYmz6c3"
      },
      "outputs": [],
      "source": [
        "optim.step()\n",
        "optim.zero_grad()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVMQ5K1Qz6c4"
      },
      "source": [
        "## Further considerations: Target parameters\n",
        "\n",
        "Another important aspect to consider is the presence of target parameters\n",
        "in off-policy algorithms like DDPG. Target parameters typically represent\n",
        "a delayed or smoothed version of the parameters over time, and they play\n",
        "a crucial role in value estimation during policy training. Utilizing target\n",
        "parameters for policy training often proves to be significantly more\n",
        "efficient compared to using the current configuration of value network\n",
        "parameters. Generally, managing target parameters is handled by the loss\n",
        "module, relieving users of direct concern. However, it remains the user's\n",
        "responsibility to update these values as necessary based on specific\n",
        "requirements. TorchRL offers a couple of updaters, namely\n",
        ":class:`~torchrl.objectives.HardUpdate` and\n",
        ":class:`~torchrl.objectives.SoftUpdate`,\n",
        "which can be easily instantiated without requiring in-depth\n",
        "knowledge of the underlying mechanisms of the loss module.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Y9Lf62Mlz6c4"
      },
      "outputs": [],
      "source": [
        "from torchrl.objectives import SoftUpdate\n",
        "\n",
        "updater = SoftUpdate(ddpg_loss, eps=0.99)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RDHBPoXz6c4"
      },
      "source": [
        "In your training loop, you will need to update the target parameters at each\n",
        "optimization step or each collection step:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WOjY1dxb0xCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "No0VsKe2z6c4"
      },
      "outputs": [],
      "source": [
        "updater.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNNV2q1Yz6c5"
      },
      "source": [
        "This is all you need to know about loss modules to get started!\n",
        "\n",
        "To further explore the topic, have a look at:\n",
        "\n",
        "- The `loss module reference page <ref_objectives>`;\n",
        "- The `Coding a DDPG loss tutorial <coding_ddpg>`;\n",
        "- Losses in action in `PPO <coding_ppo>` or `DQN <coding_dqn>`.\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}